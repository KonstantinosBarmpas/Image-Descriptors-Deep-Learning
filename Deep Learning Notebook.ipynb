{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FINAL_SUBMISSION(1).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "scylC1qNuBY0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Project Code - Konstantinos Barmpas\n",
        "\n",
        "\n",
        "This projects outlines a proposed neural network model for generation of image descriptors in the Euclidean Space. With these descriptors, matching, verification and retrieval tasks should be performed successfully. The baseline code consists of a shallow UNet for the de-noising of the images followed by a triple L2-Net responsible for the generation of the image descriptors using triplet loss. In our proposed improved method, the image de-noising model is an TernausNet while the descriptor generation model is the baseline L2-Net fine-tuned using Tree of Parzen Estimators(TPE) method and hard-mining for the triplet loss function. For the evaluation and comparison of the two approaches, the HPatches benchmark was used."
      ]
    },
    {
      "metadata": {
        "id": "eX8tbn3w1BG4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##!Before running the code read the instructions in appendix report!\n",
        "\n",
        "In section 1 the code trains and tests the baseline and final model. \\\\\n",
        "In section 2 there are different techniques used while experimenting "
      ]
    },
    {
      "metadata": {
        "id": "ZqU7SXqM35OG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##SECTION 1\n",
        "\n",
        "The code trains and tests the baseline and final model."
      ]
    },
    {
      "metadata": {
        "id": "iamuRgeiNLjW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Safety Check"
      ]
    },
    {
      "metadata": {
        "id": "ZZG4BqkENEyd",
        "colab_type": "code",
        "outputId": "389907ca-2cab-4c4b-a467-004945f361f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "cell_type": "code",
      "source": [
        "# Taken from\n",
        "# https://stackoverflow.com/questions/48750199/google-colaboratory-misleading-information-about-its-gpu-only-5-ram-available\n",
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# Colab only provides one GPU and it is not always guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "  process = psutil.Process(os.getpid())\n",
        "  print(\"RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gputil in /usr/local/lib/python2.7/dist-packages (1.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python2.7/dist-packages (0.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BBvIvBoyg68g",
        "colab_type": "code",
        "outputId": "4ba4f62f-12a1-409a-c9a9-6e5924b25957",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "cell_type": "code",
      "source": [
        "printm()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('RAM Free: 12.8 GB', ' | Proc size: 152.1 MB')\n",
            "GPU RAM Free: 11441MB | Used: 0MB | Util   0% | Total 11441MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OMiynJ7p-zI8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Downloading Functions and Data\n"
      ]
    },
    {
      "metadata": {
        "id": "yV1m-9ZGuKGj",
        "colab_type": "code",
        "outputId": "11ff8b6f-25b7-49f3-d471-c5ca3163bd49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        }
      },
      "cell_type": "code",
      "source": [
        "# Clone repo\n",
        "!git clone https://github.com/MatchLab-Imperial/keras_triplet_descriptor\n",
        "# Change directory\n",
        "%cd /content/keras_triplet_descriptor \n",
        "# Download data\n",
        "!wget -O hpatches_data.zip https://imperialcollegelondon.box.com/shared/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip\n",
        "# Extract data\n",
        "!unzip -q ./hpatches_data.zip\n",
        "!rm ./hpatches_data.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'keras_triplet_descriptor'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects:  33% (1/3)   \u001b[K\rremote: Counting objects:  66% (2/3)   \u001b[K\rremote: Counting objects: 100% (3/3)   \u001b[K\rremote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 181 (delta 0), reused 1 (delta 0), pack-reused 178\u001b[K\n",
            "Receiving objects: 100% (181/181), 149.87 MiB | 21.48 MiB/s, done.\n",
            "Resolving deltas: 100% (65/65), done.\n",
            "Checking out files: 100% (69/69), done.\n",
            "/content/keras_triplet_descriptor\n",
            "--2019-03-22 15:26:29--  https://imperialcollegelondon.box.com/shared/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip\n",
            "Resolving imperialcollegelondon.box.com (imperialcollegelondon.box.com)... 107.152.27.197\n",
            "Connecting to imperialcollegelondon.box.com (imperialcollegelondon.box.com)|107.152.27.197|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /public/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip [following]\n",
            "--2019-03-22 15:26:30--  https://imperialcollegelondon.box.com/public/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip\n",
            "Reusing existing connection to imperialcollegelondon.box.com:443.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://imperialcollegelondon.app.box.com/public/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip [following]\n",
            "--2019-03-22 15:26:30--  https://imperialcollegelondon.app.box.com/public/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip\n",
            "Resolving imperialcollegelondon.app.box.com (imperialcollegelondon.app.box.com)... 107.152.27.199, 107.152.26.199\n",
            "Connecting to imperialcollegelondon.app.box.com (imperialcollegelondon.app.box.com)|107.152.27.199|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://public.boxcloud.com/d/1/b1!-CqsuX_AtpQ0fExsj175pCy89mByRMTMaFGVo7UVabb180zeGUeVqZXw9ZYhrDsLs5kM5ftkln-sAxyTvo0ld3B4J_MQP6NsuA58gA0yvA22mOlBjBuTaLBYeLP0XTIE6ysVhkole32L-GPk6rhQlHqnMvSvq6KKh9nqKZyI0tEuT7OfJ91mMk4rGmP5yxrpsGoO2JpyH3yBlgZGSVoVkLPlQ0q0htWy9RgR7P9Rl0zxxOnas_Myz8cBa1C2uZAqUjZ7i_oiVsgJXewqr7F_L7HeNhQuBKWRbCm_w2NhOzYlyC2F5C0SfFhbDeLo5rex214uxJ4fqAzABMGGL4eOvjb2ZAgy899mRraZb5qQRX7OgccXIQFFOSNyXK9FN0fgErGVkzuMh4XN2y9lAbq7tK34fG59_apDJAB72QX6_6GvS5Asr7EYtnYHYbieJUeClCSMD4YMRGNPXo7JDVvk9QzAjq65B1EgQMFBm-FXN7WojAlh7QynGQnWcU2VX68WBdvB2VuFVK2pCyjRztQVZLAcb2-C-zZs-G4BbyOR2RBBQXcd4zAydNltythnvzl4eIsT4PT9rQSLF9hsQu0BTWas1iAddig6XwnSnjVHmnrm0ag2FNovH379cj3474T9Utwj7E1olQm_Y0eF_s9UqVxs6zpQ4zDOGk8q3eYhud2dxwPZps4yBH0jbSIYeWLftotMPtllZN5q6yFpH1WXMtQ1FPvpy3jIPD9rbq4LsfTNP-Ie1diaMQmtyMBJBBQzb0Nm4_7uX_8spBW7H1inH61nQrp1aTQq-hVXFyMCNEpcrVgxMDwszpd5pFNT3bk8YDNzRbZuN7cV3JyWS_hqcdFIPxuSEG907Uj0-tMMwhl92OaFkSA3_I9mgP4dAL0dwF3iXDWAcNREDkrn9O2K4KVhIsjBUd3GjSNny7Fnn7s9j1gmAFMnNGwIJqiYvsT6nBLMXPTYm0Av2xM7NiO0BYHx_0P5Vr73Nxjn9LBwZ8M4EcZcubsZlEX08ANXYCktjM260KSt_oLR2XYemVzJMMEL1819hOpW-kCXUkMaoLBknubBPEhO3dXm_nL8RbPIcbjka4IGPZ2UVGJ49krGDw86uzFffaIbvgjsecAxvI8hJh1K3MQ3MzVQPE8SEMUtzDL_2wUeUG2Fbk7KbA1qZaBelV5BVMBNWfMLUqT2ymfrS-1JeEIc97yNWTYpyA_e7E_wdR6LIbgwJ90e7u__QDc5PJE2gZ7uUu2836eXf-l6d4xRcASlXgp66r7bLwpOrPTcBogE1qWKX7tRxpAOVopAQDP5AV1DmHwwhZIzaZVExq6AD1wRibi0TTuhiB7D0n2mYhSkTeuZT2gVM-VJ_CmkgLsksp9hWN3Z0wXwc9SPUb3h7DboZb1rYeeh1fU3FCgHqf8XxzQcN50-Xt2AnpyV-e8d6PTpU9lwVvENJ2b_kYVDO5MgV87cdmwJzoN8jINTKLIV3H6lwlcImg71q2t88L5aBc_UR6dj/download [following]\n",
            "--2019-03-22 15:26:30--  https://public.boxcloud.com/d/1/b1!-CqsuX_AtpQ0fExsj175pCy89mByRMTMaFGVo7UVabb180zeGUeVqZXw9ZYhrDsLs5kM5ftkln-sAxyTvo0ld3B4J_MQP6NsuA58gA0yvA22mOlBjBuTaLBYeLP0XTIE6ysVhkole32L-GPk6rhQlHqnMvSvq6KKh9nqKZyI0tEuT7OfJ91mMk4rGmP5yxrpsGoO2JpyH3yBlgZGSVoVkLPlQ0q0htWy9RgR7P9Rl0zxxOnas_Myz8cBa1C2uZAqUjZ7i_oiVsgJXewqr7F_L7HeNhQuBKWRbCm_w2NhOzYlyC2F5C0SfFhbDeLo5rex214uxJ4fqAzABMGGL4eOvjb2ZAgy899mRraZb5qQRX7OgccXIQFFOSNyXK9FN0fgErGVkzuMh4XN2y9lAbq7tK34fG59_apDJAB72QX6_6GvS5Asr7EYtnYHYbieJUeClCSMD4YMRGNPXo7JDVvk9QzAjq65B1EgQMFBm-FXN7WojAlh7QynGQnWcU2VX68WBdvB2VuFVK2pCyjRztQVZLAcb2-C-zZs-G4BbyOR2RBBQXcd4zAydNltythnvzl4eIsT4PT9rQSLF9hsQu0BTWas1iAddig6XwnSnjVHmnrm0ag2FNovH379cj3474T9Utwj7E1olQm_Y0eF_s9UqVxs6zpQ4zDOGk8q3eYhud2dxwPZps4yBH0jbSIYeWLftotMPtllZN5q6yFpH1WXMtQ1FPvpy3jIPD9rbq4LsfTNP-Ie1diaMQmtyMBJBBQzb0Nm4_7uX_8spBW7H1inH61nQrp1aTQq-hVXFyMCNEpcrVgxMDwszpd5pFNT3bk8YDNzRbZuN7cV3JyWS_hqcdFIPxuSEG907Uj0-tMMwhl92OaFkSA3_I9mgP4dAL0dwF3iXDWAcNREDkrn9O2K4KVhIsjBUd3GjSNny7Fnn7s9j1gmAFMnNGwIJqiYvsT6nBLMXPTYm0Av2xM7NiO0BYHx_0P5Vr73Nxjn9LBwZ8M4EcZcubsZlEX08ANXYCktjM260KSt_oLR2XYemVzJMMEL1819hOpW-kCXUkMaoLBknubBPEhO3dXm_nL8RbPIcbjka4IGPZ2UVGJ49krGDw86uzFffaIbvgjsecAxvI8hJh1K3MQ3MzVQPE8SEMUtzDL_2wUeUG2Fbk7KbA1qZaBelV5BVMBNWfMLUqT2ymfrS-1JeEIc97yNWTYpyA_e7E_wdR6LIbgwJ90e7u__QDc5PJE2gZ7uUu2836eXf-l6d4xRcASlXgp66r7bLwpOrPTcBogE1qWKX7tRxpAOVopAQDP5AV1DmHwwhZIzaZVExq6AD1wRibi0TTuhiB7D0n2mYhSkTeuZT2gVM-VJ_CmkgLsksp9hWN3Z0wXwc9SPUb3h7DboZb1rYeeh1fU3FCgHqf8XxzQcN50-Xt2AnpyV-e8d6PTpU9lwVvENJ2b_kYVDO5MgV87cdmwJzoN8jINTKLIV3H6lwlcImg71q2t88L5aBc_UR6dj/download\n",
            "Resolving public.boxcloud.com (public.boxcloud.com)... 107.152.26.200\n",
            "Connecting to public.boxcloud.com (public.boxcloud.com)|107.152.26.200|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4088106554 (3.8G) [application/zip]\n",
            "Saving to: ‘hpatches_data.zip’\n",
            "\n",
            "hpatches_data.zip   100%[===================>]   3.81G  22.8MB/s    in 3m 14s  \n",
            "\n",
            "2019-03-22 15:29:45 (20.1 MB/s) - ‘hpatches_data.zip’ saved [4088106554/4088106554]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BqSnkHQ5Wb4q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Install Hyperas\n",
        "\n",
        "This is necessary for the PTE method to tune hyper parameters for the L2-Net\n",
        " "
      ]
    },
    {
      "metadata": {
        "id": "W-sYv3VAWY3G",
        "colab_type": "code",
        "outputId": "dddbf45c-bae9-40a1-f140-19e5646b2175",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1226
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install hyperas"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting hyperas\n",
            "  Downloading https://files.pythonhosted.org/packages/c5/f2/6f3014fea05b0011ab58216d3ae6c82ddf73359179aa7c764cabf3088576/hyperas-0.4.1-py2-none-any.whl\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python2.7/dist-packages (from hyperas) (0.1.2)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python2.7/dist-packages (from hyperas) (2.2.4)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python2.7/dist-packages (from hyperas) (5.4.1)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python2.7/dist-packages (from hyperas) (4.4.0)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python2.7/dist-packages (from hyperas) (1.0.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python2.7/dist-packages (from hyperas) (0.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python2.7/dist-packages (from hyperopt->hyperas) (1.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python2.7/dist-packages (from hyperopt->hyperas) (1.14.6)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python2.7/dist-packages (from hyperopt->hyperas) (3.7.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python2.7/dist-packages (from hyperopt->hyperas) (2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python2.7/dist-packages (from hyperopt->hyperas) (4.28.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python2.7/dist-packages (from hyperopt->hyperas) (0.16.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python2.7/dist-packages (from hyperopt->hyperas) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python2.7/dist-packages (from keras->hyperas) (1.0.7)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python2.7/dist-packages (from keras->hyperas) (1.0.9)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python2.7/dist-packages (from keras->hyperas) (2.8.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python2.7/dist-packages (from keras->hyperas) (3.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python2.7/dist-packages (from nbconvert->hyperas) (2.10)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python2.7/dist-packages (from nbconvert->hyperas) (0.5.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python2.7/dist-packages (from nbconvert->hyperas) (0.4.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python2.7/dist-packages (from nbconvert->hyperas) (3.1.0)\n",
            "Requirement already satisfied: mistune>=0.8.1 in /usr/local/lib/python2.7/dist-packages (from nbconvert->hyperas) (0.8.4)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python2.7/dist-packages (from nbconvert->hyperas) (4.4.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python2.7/dist-packages (from nbconvert->hyperas) (2.1.3)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from nbconvert->hyperas) (1.4.2)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python2.7/dist-packages (from nbconvert->hyperas) (4.3.2)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python2.7/dist-packages (from nbformat->hyperas) (2.6.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python2.7/dist-packages (from nbformat->hyperas) (0.2.0)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python2.7/dist-packages (from jupyter->hyperas) (7.4.2)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python2.7/dist-packages (from jupyter->hyperas) (4.4.3)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python2.7/dist-packages (from jupyter->hyperas) (5.2.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python2.7/dist-packages (from jupyter->hyperas) (4.6.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python2.7/dist-packages (from jupyter->hyperas) (5.2.2)\n",
            "Requirement already satisfied: configparser>=3.5; python_version == \"2.7\" in /usr/local/lib/python2.7/dist-packages (from entrypoints->hyperas) (3.7.3)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python2.7/dist-packages (from networkx->hyperopt->hyperas) (4.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python2.7/dist-packages (from jinja2->nbconvert->hyperas) (1.1.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python2.7/dist-packages (from bleach->nbconvert->hyperas) (0.5.1)\n",
            "Requirement already satisfied: enum34; python_version == \"2.7\" in /usr/local/lib/python2.7/dist-packages (from traitlets>=4.2->nbconvert->hyperas) (1.1.6)\n",
            "Requirement already satisfied: functools32; python_version == \"2.7\" in /usr/local/lib/python2.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat->hyperas) (3.2.3.post2)\n",
            "Requirement already satisfied: ipython<6.0.0,>=4.0.0; python_version < \"3.3\" in /usr/local/lib/python2.7/dist-packages (from ipywidgets->jupyter->hyperas) (5.5.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.4.0 in /usr/local/lib/python2.7/dist-packages (from ipywidgets->jupyter->hyperas) (3.4.2)\n",
            "Requirement already satisfied: jupyter-client>=4.1 in /usr/local/lib/python2.7/dist-packages (from qtconsole->jupyter->hyperas) (5.2.4)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.0 in /usr/local/lib/python2.7/dist-packages (from jupyter-console->jupyter->hyperas) (1.0.15)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python2.7/dist-packages (from ipykernel->jupyter->hyperas) (4.5.3)\n",
            "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python2.7/dist-packages (from notebook->jupyter->hyperas) (0.8.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python2.7/dist-packages (from ipython<6.0.0,>=4.0.0; python_version < \"3.3\"->ipywidgets->jupyter->hyperas) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python2.7/dist-packages (from ipython<6.0.0,>=4.0.0; python_version < \"3.3\"->ipywidgets->jupyter->hyperas) (0.7.5)\n",
            "Requirement already satisfied: backports.shutil-get-terminal-size; python_version == \"2.7\" in /usr/local/lib/python2.7/dist-packages (from ipython<6.0.0,>=4.0.0; python_version < \"3.3\"->ipywidgets->jupyter->hyperas) (1.0.0)\n",
            "Requirement already satisfied: pathlib2; python_version == \"2.7\" or python_version == \"3.3\" in /usr/local/lib/python2.7/dist-packages (from ipython<6.0.0,>=4.0.0; python_version < \"3.3\"->ipywidgets->jupyter->hyperas) (2.3.3)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python2.7/dist-packages (from ipython<6.0.0,>=4.0.0; python_version < \"3.3\"->ipywidgets->jupyter->hyperas) (4.6.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python2.7/dist-packages (from ipython<6.0.0,>=4.0.0; python_version < \"3.3\"->ipywidgets->jupyter->hyperas) (40.8.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python2.7/dist-packages (from jupyter-client>=4.1->qtconsole->jupyter->hyperas) (17.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python2.7/dist-packages (from jupyter-client>=4.1->qtconsole->jupyter->hyperas) (2.5.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python2.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter->hyperas) (0.1.7)\n",
            "Requirement already satisfied: singledispatch in /usr/local/lib/python2.7/dist-packages (from tornado>=4.0->ipykernel->jupyter->hyperas) (3.4.0.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python2.7/dist-packages (from tornado>=4.0->ipykernel->jupyter->hyperas) (2019.3.9)\n",
            "Requirement already satisfied: backports_abc>=0.4 in /usr/local/lib/python2.7/dist-packages (from tornado>=4.0->ipykernel->jupyter->hyperas) (0.5)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python2.7/dist-packages (from terminado>=0.3.3; sys_platform != \"win32\"->notebook->jupyter->hyperas) (0.6.0)\n",
            "Requirement already satisfied: scandir; python_version < \"3.5\" in /usr/local/lib/python2.7/dist-packages (from pathlib2; python_version == \"2.7\" or python_version == \"3.3\"->ipython<6.0.0,>=4.0.0; python_version < \"3.3\"->ipywidgets->jupyter->hyperas) (1.10.0)\n",
            "Installing collected packages: hyperas\n",
            "Successfully installed hyperas-0.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Rjyr96hR_4wS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Importing Necessary Modules\n",
        "\n",
        "We now import the modules we will use in this baseline code. "
      ]
    },
    {
      "metadata": {
        "id": "o0KYfe-at9KN",
        "colab_type": "code",
        "outputId": "4dcd2290-fb4d-45d8-c507-94c579994e09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import json\n",
        "import os\n",
        "import glob\n",
        "import time\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Input, Lambda, Reshape\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization \n",
        "from keras.layers import Input, UpSampling2D, concatenate  \n",
        "from read_data import HPatches, DataGeneratorDesc, hpatches_sequence_folder, DenoiseHPatches, tps\n",
        "from utils import generate_desc_csv, plot_denoise, plot_triplet\n",
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "from hyperopt import Trials, STATUS_OK, tpe\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras.models import Sequential\n",
        "from keras.utils import np_utils\n",
        "from hyperas import optim\n",
        "from hyperas.distributions import choice, uniform\n",
        "from keras.layers import Lambda\n",
        "from keras.layers import Conv2D\n",
        "from keras.models import Model\n",
        "from keras.layers import Conv2DTranspose\n",
        "from keras.layers import UpSampling2D\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Concatenate\n",
        "from keras.applications import VGG16\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import argparse\n",
        "import re\n",
        "import os, glob, datetime\n",
        "import numpy as np\n",
        "from keras.layers import  Input,Conv2D,BatchNormalization,Activation,Subtract\n",
        "from keras.models import Model, load_model\n",
        "from keras.callbacks import CSVLogger, ModelCheckpoint, LearningRateScheduler\n",
        "from keras.optimizers import Adam\n",
        "import keras.backend as K\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "AFG0LyAct_-l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The `read_data` and `utils` imports are functions provided in the repository we just cloned. You can navigate through the *File tab* and check what those functions do for a better understanding.\n",
        "\n",
        "![texto del enlace](https://i.ibb.co/HnfSvfT/filetab.png)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "2Y61ZKWZ7o5k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We also fix the seeds of the pseudo-random number generators to have reproducible results. The idea of fixing the seed is having the same results every time the algorithm is run if there are no changes in the code."
      ]
    },
    {
      "metadata": {
        "id": "NXL31ez-AT5h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "random.seed(1234)\n",
        "np.random.seed(1234)\n",
        "tf.set_random_seed(1234)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_OqFkNujBGzf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we load the data. The original HPatches dataset has several splits, which are used to separate the available sequences in train sequences and test sequences. For our experiments in N-HPatches we use the same splits as in HPatches. Specifically, we load (and report results) using the split `'a'`:\n"
      ]
    },
    {
      "metadata": {
        "id": "ABKDHB9RApZk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "hpatches_dir = './hpatches'\n",
        "splits_path = './splits.json'\n",
        "\n",
        "splits_json = json.load(open(splits_path, 'rb'))\n",
        "split = splits_json['a']\n",
        "\n",
        "train_fnames = split['train']\n",
        "test_fnames = split['test']\n",
        "\n",
        "seqs = glob.glob(hpatches_dir+'/*')\n",
        "seqs = [os.path.abspath(p) for p in seqs]   \n",
        "seqs_train = list(filter(lambda x: x.split('/')[-1] in train_fnames, seqs)) \n",
        "seqs_test = list(filter(lambda x: x.split('/')[-1] in split['test'], seqs)) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nWRowqAQW52k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model and loss - Baseline code\n"
      ]
    },
    {
      "metadata": {
        "id": "3tQ8d56BW2NL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_denoise_model(shape):\n",
        "    \n",
        "  inputs = Input(shape)\n",
        "  \n",
        "  ## Encoder starts\n",
        "  conv1 = Conv2D(16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
        "  pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "  \n",
        "  ## Bottleneck\n",
        "  conv2 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
        "\n",
        "  ## Now the decoder starts\n",
        "  up3 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv2))\n",
        "  merge3 = concatenate([conv1,up3], axis = -1)\n",
        "  conv3 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge3)\n",
        "    \n",
        "  conv4 = Conv2D(1, 3,  padding = 'same')(conv3)\n",
        "\n",
        "  shallow_net = Model(inputs = inputs, outputs = conv4)\n",
        "  \n",
        "  return shallow_net\n",
        "\n",
        "\n",
        "\n",
        "def get_descriptor_model(shape):\n",
        "  \n",
        "  '''Architecture copies HardNet architecture'''\n",
        "  \n",
        "  init_weights = keras.initializers.he_normal()\n",
        "  \n",
        "  descriptor_model = Sequential()\n",
        "  descriptor_model.add(Conv2D(32, 3, padding='same', input_shape=shape, use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('relu'))\n",
        "\n",
        "  descriptor_model.add(Conv2D(32, 3, padding='same', use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('relu'))\n",
        "\n",
        "  descriptor_model.add(Conv2D(64, 3, padding='same', strides=2, use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('relu'))\n",
        "\n",
        "  descriptor_model.add(Conv2D(64, 3, padding='same', use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('relu'))\n",
        "\n",
        "  descriptor_model.add(Conv2D(128, 3, padding='same', strides=2,  use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('relu'))\n",
        "\n",
        "  descriptor_model.add(Conv2D(128, 3, padding='same', use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('relu'))\n",
        "  descriptor_model.add(Dropout(0.3))\n",
        "\n",
        "  descriptor_model.add(Conv2D(128, 8, padding='valid', use_bias = True, kernel_initializer=init_weights))\n",
        "  \n",
        "  # Final descriptor reshape\n",
        "  descriptor_model.add(Reshape((128,)))\n",
        "  \n",
        "  return descriptor_model\n",
        "  \n",
        "  \n",
        "def triplet_loss(x):\n",
        "  \n",
        "  output_dim = 128\n",
        "  a, p, n = x\n",
        "  _alpha = 1.0\n",
        "  positive_distance = K.mean(K.square(a - p), axis=-1)\n",
        "  negative_distance = K.mean(K.square(a - n), axis=-1)\n",
        "  \n",
        "  return K.expand_dims(K.maximum(0.0, positive_distance - negative_distance + _alpha), axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qeWik0vMEtuC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Models and loss - Proposed method"
      ]
    },
    {
      "metadata": {
        "id": "kHb9fyu7XLWN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Descriptor for proposed method. L2-Net fine-tuned, PTE based changed and hard-mining triplet loss"
      ]
    },
    {
      "metadata": {
        "id": "W6QbkHnbuIUD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "  \n",
        "  shape = (32, 32, 1)\n",
        "  \n",
        "  xa = Input(shape=shape, name='a')\n",
        "  xp = Input(shape=shape, name='p')\n",
        "  xn = Input(shape=shape, name='n')\n",
        "  \n",
        "  init_weights = keras.initializers.he_normal()\n",
        "  \n",
        "  descriptor_model = Sequential()\n",
        "  descriptor_model.add(Conv2D(32, 3, padding='same', input_shape=shape, use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('relu'))\n",
        "\n",
        "  descriptor_model.add(Conv2D(32, 3, padding='same', use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('relu'))\n",
        "\n",
        "  descriptor_model.add(Conv2D(64, 3, padding='same', strides=2, use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('sigmoid'))\n",
        "\n",
        "  descriptor_model.add(Conv2D(64, 3, padding='same', use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('sigmoid'))\n",
        "\n",
        "  descriptor_model.add(Conv2D(128, 3, padding='same', strides=2,  use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('relu'))\n",
        "\n",
        "  descriptor_model.add(Conv2D(128, 3, padding='same', use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('relu'))\n",
        "  descriptor_model.add(Dropout(0.5))\n",
        "\n",
        "  descriptor_model.add(Conv2D(128, 8, padding='valid', use_bias = True, kernel_initializer=init_weights))\n",
        "  \n",
        "  # Final descriptor reshape\n",
        "  descriptor_model.add(Reshape((128,)))\n",
        "  \n",
        "  return descriptor_model;\n",
        "  \n",
        "  \n",
        "def triplet_loss(x):\n",
        "  \n",
        "  output_dim = 128\n",
        "  a, p, n = x\n",
        "  _alpha = 1.0\n",
        "  positive_distance = K.mean(K.square(a - p), axis=-1)\n",
        "  negative_distance = K.mean(K.square(a - n), axis=-1)\n",
        "  \n",
        "  return K.expand_dims(K.maximum(0.0, positive_distance - negative_distance + _alpha), axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tCmiTGLKYFQs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Denoiser for proposed method. Improved TaurusNet. UNet with VGG16 as the enconder part frozen at ImageNet weights"
      ]
    },
    {
      "metadata": {
        "id": "PJI3tuWyHSkN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "backbones = {\"vgg16\": VGG16}\n",
        "\n",
        "#Get the pre-trained UNet with VGG16 encoder\n",
        "def Unet(input_tensor=None):\n",
        "   \n",
        "    #Specifying the upsample rates\n",
        "    upsample_rates=(2,2,2,2,2)\n",
        "    \n",
        "    #Specify decoding filters\n",
        "    decoder_filters=(256,128,64,32,16)\n",
        "    \n",
        "    #Get the pre-trained vgg\n",
        "    vgg = get_vgg16_from_keras('vgg16', input_shape=(32,32,3), input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "\n",
        "    #Define the skipping connections\n",
        "    skip_connections = ('block5_conv3', 'block4_conv3', 'block3_conv3', 'block2_conv2', 'block1_conv2')\n",
        "    \n",
        "    #Input of the vgg\n",
        "    input = vgg.input\n",
        "    x = vgg.output\n",
        "\n",
        "    #Define the upsample model\n",
        "    up_block = Upsample2D_block\n",
        "\n",
        "    #Turn layer names to indices\n",
        "    skip_connection_idx = ([get_layer_number(vgg, l) if isinstance(l, str) else l\n",
        "                               for l in skip_connections])\n",
        "\n",
        "    #5 Upsample blocks\n",
        "    for i in range(5):\n",
        "\n",
        "        #Check if skipping a connection\n",
        "        skip_connection = None\n",
        "        if i < len(skip_connection_idx):\n",
        "            skip_connection = vgg.layers[skip_connection_idx[i]].output\n",
        "            \n",
        "        #Upsample\n",
        "        upsample_rate = to_tuple(upsample_rates[i])\n",
        "\n",
        "        x = up_block(decoder_filters[i], i, upsample_rate=upsample_rate, skip=skip_connection)(x)\n",
        "    \n",
        "    #Create the final 1 channel denoised image\n",
        "    x = Conv2D(1, (3,3), padding='same', name='final_conv')(x)\n",
        "    x = Activation('linear', name='linear')(x)\n",
        "\n",
        "    #Final combined model\n",
        "    model = Model(input, x)\n",
        "\n",
        "\n",
        "    #Freeze the encoder model\n",
        "    for layer in vgg.layers:\n",
        "        vgg.trainable = False\n",
        "\n",
        "    return model\n",
        "  \n",
        "\n",
        "#Get the pre-trained vgg    \n",
        "def get_vgg16_from_keras(name, *args, **kwargs):\n",
        "   return backbones[name](*args, **kwargs)\n",
        "  \n",
        "#Function for Convolution, Relu and Batch normalization\n",
        "def ConvRelu(filters, kernel_size, conv_name='conv', bn_name='bn', relu_name='relu'):\n",
        "    def layer(x):\n",
        "        x = Conv2D(filters, kernel_size, padding=\"same\", name=conv_name, use_bias=False)(x)\n",
        "        x = BatchNormalization(name=bn_name)(x)\n",
        "        x = Activation('relu', name=relu_name)(x)\n",
        "        return x\n",
        "    return layer\n",
        "\n",
        "#Function for upsampling\n",
        "def Upsample2D_block(filters, stage, kernel_size=(3,3), upsample_rate=(2,2), skip=None):\n",
        "\n",
        "    def layer(input_tensor):\n",
        "\n",
        "        conv_name, bn_name, relu_name, up_name = block_name(stage)\n",
        "\n",
        "        x = UpSampling2D(size=upsample_rate, name=up_name)(input_tensor)\n",
        "\n",
        "        if skip is not None:\n",
        "            x = Concatenate()([x, skip])\n",
        "\n",
        "        x = ConvRelu(filters, kernel_size, conv_name=conv_name + '1', bn_name=bn_name + '1', relu_name=relu_name + '1')(x)\n",
        "\n",
        "        x = ConvRelu(filters, kernel_size, conv_name=conv_name + '2', bn_name=bn_name + '2', relu_name=relu_name + '2')(x)\n",
        "\n",
        "        return x\n",
        "    return layer\n",
        "  \n",
        "#Get layer number based on the name  \n",
        "def get_layer_number(model, layer_name):\n",
        "    for i, l in enumerate(model.layers):\n",
        "        if l.name == layer_name:\n",
        "            return i\n",
        "    raise ValueError('No layer with name {} in  model {}.'.format(layer_name, model.name))\n",
        "    \n",
        "#Use names to find index of current perfoming block\n",
        "def block_name(stage):\n",
        "    conv_name = 'decoder_stage{}_conv'.format(stage)\n",
        "    bn_name = 'decoder_stage{}_bn'.format(stage)\n",
        "    relu_name = 'decoder_stage{}_relu'.format(stage)\n",
        "    up_name = 'decoder_stage{}_upsample'.format(stage)\n",
        "    return conv_name, bn_name, relu_name, up_name\n",
        "\n",
        "#Tuple check   \n",
        "def to_tuple(x):\n",
        "    if isinstance(x, tuple):\n",
        "        if len(x) == 2:\n",
        "            return x\n",
        "    elif np.isscalar(x):\n",
        "        return (x, x)\n",
        "\n",
        "    raise ValueError('Value should be tuple of length 2 or int value, got \"{}\"'.format(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "52MoYymiYTl0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Denoising Image Patches \n"
      ]
    },
    {
      "metadata": {
        "id": "8ZjdJ7kvYWcF",
        "colab_type": "code",
        "outputId": "10bdc60f-ea36-4932-a4f8-1b489ea6487b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "cell_type": "code",
      "source": [
        "denoise_generator = DenoiseHPatches(random.sample(seqs_train, 3), batch_size=50)\n",
        "denoise_generator_val = DenoiseHPatches(random.sample(seqs_test, 1), batch_size=50)\n",
        "\n",
        "# Uncomment following lines for using all the data to train the denoising model\n",
        "# denoise_generator = DenoiseHPatches(seqs_train, batch_size=50)\n",
        "# denoise_generator_val = DenoiseHPatches(seqs_test, batch_size=50)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [00:03<00:00,  1.12it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "kYeTHF1RH6od",
        "colab_type": "code",
        "outputId": "04beb39d-fcb6-4539-cf5f-982800240d61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2754
        }
      },
      "cell_type": "code",
      "source": [
        "#Concatenate the input 32x32x11 image to create a 3-channel input for VGG16\n",
        "img_input = Input(shape=(32,32,1))\n",
        "img_conc = Concatenate()([img_input, img_input, img_input]) \n",
        "\n",
        "# build UNet with pre-trained VGG16 as the encoder\n",
        "denoise_model = Unet(input_tensor=img_conc)\n",
        "denoise_model.compile('Adam', 'mean_absolute_error', ['mae'])\n",
        "denoise_model.summary()\n",
        "\n",
        "# Uncomment following lines for using baseline model\n",
        "#shape = (32, 32, 1)\n",
        "#denoise_model = get_denoise_model(shape)\n",
        "#sgd = keras.optimizers.SGD(lr=0.00001, momentum=0.9, nesterov=True)\n",
        "#denoise_model.compile(loss='mean_absolute_error', optimizer=sgd, metrics=['mae'])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "58900480/58889256 [==============================] - 1s 0us/step\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 32, 32, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 32, 32, 3)    0           input_1[0][0]                    \n",
            "                                                                 input_1[0][0]                    \n",
            "                                                                 input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, 32, 32, 64)   1792        concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, 32, 32, 64)   36928       block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_pool (MaxPooling2D)      (None, 16, 16, 64)   0           block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv1 (Conv2D)           (None, 16, 16, 128)  73856       block1_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv2 (Conv2D)           (None, 16, 16, 128)  147584      block2_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, 8, 8, 128)    0           block2_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv1 (Conv2D)           (None, 8, 8, 256)    295168      block2_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv2 (Conv2D)           (None, 8, 8, 256)    590080      block3_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv3 (Conv2D)           (None, 8, 8, 256)    590080      block3_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_pool (MaxPooling2D)      (None, 4, 4, 256)    0           block3_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv1 (Conv2D)           (None, 4, 4, 512)    1180160     block3_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv2 (Conv2D)           (None, 4, 4, 512)    2359808     block4_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv3 (Conv2D)           (None, 4, 4, 512)    2359808     block4_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_pool (MaxPooling2D)      (None, 2, 2, 512)    0           block4_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv1 (Conv2D)           (None, 2, 2, 512)    2359808     block4_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv2 (Conv2D)           (None, 2, 2, 512)    2359808     block5_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv3 (Conv2D)           (None, 2, 2, 512)    2359808     block5_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_pool (MaxPooling2D)      (None, 1, 1, 512)    0           block5_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage0_upsample (UpSamp (None, 2, 2, 512)    0           block5_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 2, 2, 1024)   0           decoder_stage0_upsample[0][0]    \n",
            "                                                                 block5_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage0_conv1 (Conv2D)   (None, 2, 2, 256)    2359296     concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage0_bn1 (BatchNormal (None, 2, 2, 256)    1024        decoder_stage0_conv1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage0_relu1 (Activatio (None, 2, 2, 256)    0           decoder_stage0_bn1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage0_conv2 (Conv2D)   (None, 2, 2, 256)    589824      decoder_stage0_relu1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage0_bn2 (BatchNormal (None, 2, 2, 256)    1024        decoder_stage0_conv2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage0_relu2 (Activatio (None, 2, 2, 256)    0           decoder_stage0_bn2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage1_upsample (UpSamp (None, 4, 4, 256)    0           decoder_stage0_relu2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 4, 4, 768)    0           decoder_stage1_upsample[0][0]    \n",
            "                                                                 block4_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage1_conv1 (Conv2D)   (None, 4, 4, 128)    884736      concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage1_bn1 (BatchNormal (None, 4, 4, 128)    512         decoder_stage1_conv1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage1_relu1 (Activatio (None, 4, 4, 128)    0           decoder_stage1_bn1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage1_conv2 (Conv2D)   (None, 4, 4, 128)    147456      decoder_stage1_relu1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage1_bn2 (BatchNormal (None, 4, 4, 128)    512         decoder_stage1_conv2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage1_relu2 (Activatio (None, 4, 4, 128)    0           decoder_stage1_bn2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage2_upsample (UpSamp (None, 8, 8, 128)    0           decoder_stage1_relu2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 8, 8, 384)    0           decoder_stage2_upsample[0][0]    \n",
            "                                                                 block3_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage2_conv1 (Conv2D)   (None, 8, 8, 64)     221184      concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage2_bn1 (BatchNormal (None, 8, 8, 64)     256         decoder_stage2_conv1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage2_relu1 (Activatio (None, 8, 8, 64)     0           decoder_stage2_bn1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage2_conv2 (Conv2D)   (None, 8, 8, 64)     36864       decoder_stage2_relu1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage2_bn2 (BatchNormal (None, 8, 8, 64)     256         decoder_stage2_conv2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage2_relu2 (Activatio (None, 8, 8, 64)     0           decoder_stage2_bn2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage3_upsample (UpSamp (None, 16, 16, 64)   0           decoder_stage2_relu2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 16, 16, 192)  0           decoder_stage3_upsample[0][0]    \n",
            "                                                                 block2_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage3_conv1 (Conv2D)   (None, 16, 16, 32)   55296       concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage3_bn1 (BatchNormal (None, 16, 16, 32)   128         decoder_stage3_conv1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage3_relu1 (Activatio (None, 16, 16, 32)   0           decoder_stage3_bn1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage3_conv2 (Conv2D)   (None, 16, 16, 32)   9216        decoder_stage3_relu1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage3_bn2 (BatchNormal (None, 16, 16, 32)   128         decoder_stage3_conv2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage3_relu2 (Activatio (None, 16, 16, 32)   0           decoder_stage3_bn2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage4_upsample (UpSamp (None, 32, 32, 32)   0           decoder_stage3_relu2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 32, 32, 96)   0           decoder_stage4_upsample[0][0]    \n",
            "                                                                 block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage4_conv1 (Conv2D)   (None, 32, 32, 16)   13824       concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage4_bn1 (BatchNormal (None, 32, 32, 16)   64          decoder_stage4_conv1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage4_relu1 (Activatio (None, 32, 32, 16)   0           decoder_stage4_bn1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage4_conv2 (Conv2D)   (None, 32, 32, 16)   2304        decoder_stage4_relu1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage4_bn2 (BatchNormal (None, 32, 32, 16)   64          decoder_stage4_conv2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage4_relu2 (Activatio (None, 32, 32, 16)   0           decoder_stage4_bn2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "final_conv (Conv2D)             (None, 32, 32, 1)    145         decoder_stage4_relu2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "linear (Activation)             (None, 32, 32, 1)    0           final_conv[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 19,038,801\n",
            "Trainable params: 19,036,817\n",
            "Non-trainable params: 1,984\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "n692maM--5WX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "#To avoid over-fitting\n",
        "stop = EarlyStopping(monitor='val_loss',\n",
        "                              min_delta=0,\n",
        "                              patience=2,\n",
        "                              verbose=0, mode='auto')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ko6I4jR4YfCa",
        "colab_type": "code",
        "outputId": "cf192539-e044-4711-aef3-6c660fe1d976",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1234
        }
      },
      "cell_type": "code",
      "source": [
        "#Tran the model for 25 epochs and save it\n",
        "\n",
        "epochs = 25\n",
        "\n",
        "history=[]\n",
        "for e in range(epochs):\n",
        "  \n",
        "  denoise_history = denoise_model.fit_generator(generator=denoise_generator, \n",
        "                                                epochs=1, verbose=1, \n",
        "                                                validation_data=denoise_generator_val, callbacks=[stop])\n",
        "  history.append(denoise_history.history)\n",
        "         \n",
        "\n",
        "denoise_model.save('denoise_model_UnetVgg_25.h5')\n",
        "!curl -F \"file=@denoise_model_UnetVgg_25.h5\" https://file.io"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "  22/1458 [..............................] - ETA: 8:44 - loss: 110.8646 - mean_absolute_error: 110.8646"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-843bab4b3a7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m   denoise_history = denoise_model.fit_generator(generator=denoise_generator, \n\u001b[1;32m      8\u001b[0m                                                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                                                 validation_data=denoise_generator_val, callbacks=[stop])\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdenoise_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training_generator.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "8EaFY04jYmnv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Plot the denoiser's results"
      ]
    },
    {
      "metadata": {
        "id": "OR26ZvU1YmEU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "160bd211-2542-4db1-dbf1-4990b2b07da7"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Set empty lists\n",
        "training_loss=[]\n",
        "test_loss=[]\n",
        "\n",
        "#Get the data from the history list\n",
        "for i in range(len(history)):\n",
        "  # Get training and test loss for each one of histories\n",
        "  training_loss.append(history[i]['loss'])\n",
        "  test_loss.append(history[i]['val_loss'])\n",
        "\n",
        "# Create count of the number of epochs\n",
        "epoch_count = range(1, len(training_loss) + 1)\n",
        "\n",
        "# Visualize loss history\n",
        "plt.plot(epoch_count, training_loss, 'r--')\n",
        "plt.plot(epoch_count, test_loss, 'b--')\n",
        "plt.legend(['Training Loss', 'Validation Loss'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show();"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfsAAAFYCAYAAABUA1WSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi40LCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcv7US4rQAAIABJREFUeJzt3XtclHXe//H3cFLJQZlkEtR7I49p\nJpLmJt1pG5hpWw9TBHd1O9hSaSejA7YRtnmuXM0wz6uRIR7oeGftmti6SXorLRp20n4p1qozBXLS\nBJ37D39RrAjIwMB8eT3/8rq+1+EzH/94z/W9mOuyuFwulwAAgLF8mroAAADQuAh7AAAMR9gDAGA4\nwh4AAMMR9gAAGI6wBwDAcH5NXUBjcTiKm7oEjwsODlRBQVlTl+HV6KH76KH76KH7WmIPQ0Ks5x3j\nyt4gfn6+TV2C16OH7qOH7qOH7qOHVRH2AAAYjrAHAMBwhD0AAIYj7AEAMBxhDwCA4Qh7AAAMR9gD\nAGA4Yx+qAwDwXgsX/kVffPGZfvjhe508eVJhYZ0UFNROM2c+V+u+7777tsLCQhQR8etqxxcseEGx\nsfEKC+tUr9pWrFii9u3ba/TouHrt3xQIewBAs/PAA1MknQ3ur78+oPvvf7jO+44Y8VuFhFjP+yTV\nhx5KbJAavQlhDwDwGjk5u7R27asqKyvT/fdP0Sef7NbWrR/ozJkzuuaaKN11V4JWrFiizp07KiSk\nkzIz18li8dHBg/9PQ4feoLvuStD99yfokUceV1bWByotLdGhQwf17beH9eCDibrmmii9+uoqbd78\nN4WFdVJFRYXi43+vyMgBtda2bl26Pvjgb5Kk//7vIRo//g7t3Pmxli1bpFatWis42KaUlOnKydl1\nzjo/v8aNY8IeAFAr21VXVLu+bNKDOjkxQZJknfRH+e/IPmeb8qsGqHjpKklS67RVCpz/vH7Y/Wm9\nazlwYL/S0zMVEBCgTz7ZrUWLlsvHx0djx96quLjfVdl23748vfbaRp05c0axsb/VXXclVBk/duyo\nnn/+RX388Xa9+eZG9elzhTIz1ys9faNKS0sVH3+b4uN/X2tN3333rTZtelvLlr0iSUpIuF3XXx+t\njRszdP/9U9SvX399+OEWHT9eWO26iy/uUO9+1AVhDwDwKt26dVdAQIAkqXXr1rr//gT5+vqqsLBQ\nRUVFVbbt2bOXWrdufd5jXXllhCTJbrerpKREhw/n67LLuqpVq9Zq1aq1Lr+8T51q+uqrL9SnT9/K\nK/S+fftp//4vdf310XruuVkaNmy4oqNv1MUXd6h2XWMj7AEAtarLlXjxomW1bnNywh06OeEOt2rx\n9/eXJB058m9lZKzRypVrFBgYqAkTxp6zra9vzS/E+eW4y+WSyyX5+Pz8QzWLpa5VWeRyuSqXysvL\nZbH4aPjwkRo06Br94x9b9cQTUzR9+txq1/3qV5fW9UT1wk/vAABeqbCwUMHBwQoMDNQXX3yuI0eO\nqLy83K1jhoaG6uuvD6iiokIFBQX6/PPP6rRfjx499emne1VRUaGKigrt25enHj16atWq5fL19dOt\nt96mG24Ypm+++bradY2NK3sAgFfq3r2H2rQJ1H333aW+fSN066236YUX5ujKK/vV+5g228WKiRmu\nP/7xD/rVr8LVu3efamcH1q9fq6ysDySp8ieBt9wySg88kKAzZ1z67W9vVceOobrkko56+OFJslqD\nZLVaFR8/XmVlZeesa2wW1y/nHQxyvp9cmKymn5qgbuih++ih++ih+9zp4bvvvq2YmOHy9fXVH/4Q\nr3nzFspuv6SBK2x4ISHW845xZQ8AwC98//33Ski4Xf7+ARo2bLhXBH1tCHsAAH5hwoQ7NMHNPyJs\nbvgDPQAADEfYAwBgOMIeAADDEfYAABiOsAcANDv33HPnOQ+0Wbz4JaWnv1rt9jk5u/TUU49LkpKS\nHjlnfOPGDK1YseS859u//ysdOnRQkpSSMlU//niyvqVrxoxp+uijbfXevzEQ9gCAZicm5kZt2fL3\nKuu2bt2i6Ohhte47e/a8Cz7fhx9uUX7+IUnSM8/MUqtW53+evjfip3cAgGbnhhuG6b77JmrSpAcl\nSZ9//plCQkIUEmLX//7vDi1fvlj+/v6yWq36859nV9l35MgbtHPnTu3atVMvvviCbLaLdfHFHSpf\nWTtjxjQ5HMd04sQJ3XVXgjp2DNWbb2bqww+3KDg4WE8/PVWvvJKhkpJizZr1Z5WXl8vHx0dJScmy\nWCyaMWOawsI6af/+r9SjR08lJSXX6TMtWrRAe/fmqqLitEaPHqvhw0dq06Z3lJm5Tn5+/urWrYcS\nE5+odp27CHsAQK2uuuqiatdPmnRKEyeW//9/t9aOHec+Wvaqq05r6dKz0+Jpaf6aPz9Au3eX1ni+\n4GCbwsI6ad++T9W79xXasuXviokZLkkqLi5WSsp0hYV10rPPPq0dO7IVGBh4zjGWLHlJycnPqnv3\nHnr00QcVFtZJxcVFuvrqX+umm27Wt98eVnJyklaufFWDBl2joUNvUO/eP7/Kd/nyxbr55lt1ww3D\nlJW1WStXLtXEiffoiy8+0zPPzFRwsE2jRo1QcXGxrNbzP71Okv71rxx9/fUBvfzySp04cUK33x6v\n664bqrVrX9XcufN1ySUd9T//85Z+/PFktevcnWkg7AEAzVJMzHB98MHf1bv3Ffroo3/o5ZdXSpLa\nt2+vOXOm6/Tp0/ruu2911VUDqw37f//73+revYckKSIiUj/++KOs1iB99lme3norUxaLj4qKjp/3\n/F988Znuvfd+SVJk5ACtWrVcktSpU5fK19J26BCi0tKSWsP+88/3KSIiUpLUpk0bXXrpZcrPz1d0\n9I168snHdOONNyk6+ka1atW62nXuIuwBALWq7UpckhYtqv2P2iZMKNeECXV7M92QIdfrlVdWKibm\nRnXp8l8KCgqSJM2a9ayee26+Lr00XPPmzTnv/r98Ve1Pr4H5+9/fU1FRkVJTl6uoqEh33z2hhgp+\nfm1teXmFLJazx/vPF+PU5RUzFotFv9ysoqJcPj4WTZhwp2JibtLWrZv14IP3KTV1abXr2rVrX+s5\nasIf6AEAmqXAwIvUtWt3vfLKXyun8CWptLREl1zSUcXFxcrJ2X3e19p26BCiQ4e+kcvl0ief7JZ0\n9rW4oaFh8vHx0Ycfbqnc12Kx6PTp01X2v/zy3srJ2SVJ+te/dqtXr8vr/Vl69epTWUNZWZm+/faw\nOnf+Ly1ZkqoOHTooPn68rriir44cOVLtOndxZQ8AaLZiYoZr+vQUpaQ8W7nutttidd99E9Wly3/p\n97//g1auXKqEhEnn7JuQMElPPfWEOnYMrXyZzdChv1FS0iPat+9TjRx5i+x2u/7612Xq16+/5s9/\nrsrtgLvvvlezZj2rt99+Q35+/po6NVkVFRV1qnvJkpeUnp4mSbr00sv06KNJ6tmzlyZP/qMqKip0\n7733q02bNgoMvEj33HOn2rZtq7CwTurevYd27vz4nHXu4hW3BuG1mO6jh+6jh+6jh+5riT2s6RW3\nTOMDAGA4wh4AAMMR9gAAGI6wBwDAcB4P+5kzZyouLk7x8fHas2dPlbHt27drzJgxiouLU2pqapWx\nkydPKjo6WpmZmZ4sFwAAr+fRsN+5c6cOHjyojIwMzZgxQzNmzKgyPn36dC1cuFDp6en66KOPtH//\n/sqxl19+We3atfNkuQAAGMGjYZ+dna3o6GhJUteuXXX8+HGVlJRIkvLz89WuXTuFhobKx8dHQ4YM\nUXZ2tiTpwIED2r9/v4YOHerJcgEAMIJHw97pdCo4OLhy2WazyeFwSJIcDodsNlu1Y3PmzFFSUpIn\nSwUAwBhN+gS9ujzP54033lBERIS6dOlyQccODg6Un9+5b18yXU0PVUDd0EP30UP30UP30cOfeTTs\n7Xa7nE5n5fKxY8cUEhJS7djRo0dlt9u1detW5efna+vWrTpy5IgCAgLUsWNHDR48uMZzFRSUNc6H\naMZa4hOjGho9dB89dB89dF9L7GFNX248GvZRUVFauHCh4uPjlZeXJ7vdrrZt20qSOnfurJKSEh0+\nfFgdO3ZUVlaWnn/+eY0fP75y/4ULF6pTp061Bj0AAPiZR8M+MjJSffr0UXx8vCwWi1JSUpSZmSmr\n1aqYmBhNmzZNiYmJkqQRI0YoPDzck+UBAGAkXoRjkJY4bdXQ6KH76KH76KH7WmIPeREOAAAtGGEP\nAIDhCHsAAAxH2AMAYDjCHgAAwxH2AAAYjrAHAMBwhD0AAIYj7AEAMBxhDwCA4Qh7AAAMR9gDAGA4\nwh4AAMMR9gAAGI6wBwDAcIQ9AACGI+wBADAcYQ8AgOEIewAADEfYAwBgOMIeAADDEfYAABiOsAcA\nwHCEPQAAhiPsAQAwHGEPAIDhCHsAAAxH2AMAYDjCHgAAwxH2AAAYjrAHAMBwhD0AAIYj7AEAMBxh\nDwCA4Qh7AAAMR9gDAGA4wh4AAMMR9gAAGI6wBwDAcIQ9AACGI+wBADAcYQ8AgOEIewAADEfYAwBg\nOMIeAADD+Xn6hDNnzlRubq4sFouefPJJXXnllZVj27dv17x58+Tr66vrrrtOkydPliTNnTtXu3fv\nVkVFhe655x4NGzbM02UDAOC1PBr2O3fu1MGDB5WRkaEDBw7oySefVEZGRuX49OnTtWLFCl1yySUa\nP368brzxRjmdTn311VfKyMhQQUGBRo0aRdgDAHABPBr22dnZio6OliR17dpVx48fV0lJidq2bav8\n/Hy1a9dOoaGhkqQhQ4YoOztbv/vd7yqv/oOCgnTixAmdPn1avr6+niwdAACv5dF79k6nU8HBwZXL\nNptNDodDkuRwOGSz2c4Z8/X1VWBgoCRpw4YNuu666wh6AAAugMfv2f+Sy+Wq87abN2/Whg0btHLl\nyjptHxwcKD+/lvelICTE2tQleD166D566D566D56+DOPhr3dbpfT6axcPnbsmEJCQqodO3r0qOx2\nuyRp27ZtWrx4sZYvXy6rtW7/eQUFZQ1YuXcICbHK4Shu6jK8Gj10Hz10Hz10X0vsYU1fbjw6jR8V\nFaX3339fkpSXlye73a62bdtKkjp37qySkhIdPnxYFRUVysrKUlRUlIqLizV37lwtWbJE7du392S5\nAAAYwaNX9pGRkerTp4/i4+NlsViUkpKizMxMWa1WxcTEaNq0aUpMTJQkjRgxQuHh4ZV/hf/www9X\nHmfOnDkKCwvzZOkAAHgti+tCbpx7kZY2fSO1zGmrhkYP3UcP3UcP3dcSe9hspvEBAIDnEfYAABiO\nsAcAwHCEPQAAhiPsAQAwHGEPAIDhCHsAAAxH2AMAYDjCHgAAwxH2AAAYjrAHAMBwhD0AAIYj7AEA\nMBxhDwCA4Qh7AAAMR9gDAGA4wh4AAMMR9gAAGI6wBwDAcIQ9AACGI+wBADAcYQ8AgOEIewAADEfY\nAwBgOMIeAADDEfYAABiOsAcAwHCEPQAAhiPsAQAwHGEPAIDhCHsAAAxH2AMAYDjCHgAAwxH2AAAY\njrAHAMBwhD0AAIYj7AEAMBxhDwCA4Qh7AAAMR9gDAGC4OoX9p59+qqysLEnSX/7yF91+++3atWtX\noxYGAAAaRp3Cfvr06QoPD9euXbu0d+9eJScn68UXX2zs2gAAQAOoU9i3atVKl156qT744AONHTtW\n3bp1k48PdwAAAPAGdUrsEydOaNOmTdq8ebOuvfZaFRYWqqioqLFrAwAADaBOYf/II4/o7bff1pQp\nU9S2bVulpaXpjjvuaOTSAABAQ/Cry0a//vWvdcUVV6ht27ZyOp265pprFBkZ2di1AQCABlCnK/tn\nn31WmzZtUmFhoeLj4/Xqq69q2rRp9TrhzJkzFRcXp/j4eO3Zs6fK2Pbt2zVmzBjFxcUpNTW1TvsA\nAICa1Sns9+3bp9jYWG3atEmjRo3S/PnzdfDgwQs+2c6dO3Xw4EFlZGRoxowZmjFjRpXx6dOna+HC\nhUpPT9dHH32k/fv317oPAACoWZ3C3uVySZK2bt2q3/zmN5KkU6dOXfDJsrOzFR0dLUnq2rWrjh8/\nrpKSEklSfn6+2rVrp9DQUPn4+GjIkCHKzs6ucR8AAFC7Ot2zDw8P14gRI2Sz2XT55ZfrjTfeULt2\n7S74ZE6nU3369Klcttlscjgcatu2rRwOh2w2W5Wx/Px8FRQUnHefmgQHB8rPz/eCa/R2ISHWpi7B\n69FD99FD99FD99HDn9Up7KdPn64vv/xSXbt2lSR169ZNc+fOdfvkP80YNMY+BQVlF3xsbxcSYpXD\nUdzUZXg1eug+eug+eui+ltjDmr7c1CnsT548qS1btmjBggWyWCyKiIhQt27dLrgQu90up9NZuXzs\n2DGFhIRUO3b06FHZ7Xb5+/ufdx8AAFC7Ot2zT05OVklJieLj4zV27Fg5nU499dRTF3yyqKgovf/+\n+5KkvLw82e32yun4zp07q6SkRIcPH1ZFRYWysrIUFRVV4z4AAKB2dbqydzqdmjdvXuXy9ddfrwkT\nJlzwySIjI9WnTx/Fx8fLYrEoJSVFmZmZslqtiomJ0bRp05SYmChJGjFihMLDwxUeHn7OPgAAoO7q\nFPYnTpzQiRMn1KZNG0lSWVmZfvzxx3qd8NFHH62y3KtXr8p/Dxw4UBkZGbXuAwAA6q5OYR8XF6eb\nbrpJV1xxhaSz0+kPPfRQoxYGAAAaRp3CfsyYMYqKilJeXp4sFouSk5OVlpbW2LUBAIAGUKewl6TQ\n0FCFhoZWLvPYWgAAvEO9X0pfn9/IAwAAz6t32FssloasAwAANJIap/GHDBlSbai7XC4VFBQ0WlEA\nAKDh1Bj2r732mqfqAAAAjaTGsO/UqZOn6gAAAI2k3vfsAQCAdyDsAQAwHGEPAIDhCHsAAAxH2AMA\nYDjCHgAAwxH2AAAYjrAHAMBwhD0AAIYj7AEAMBxhDwCA4Qh7AAAMR9gDAGA4wh4AAMMR9gAAGI6w\nBwDAcIQ9AACGI+wBADAcYQ8AgOEIewAADEfYAwBgOMIeAADDEfYAABiOsAcAwHCEPQAAhiPsAQAw\nHGEPAIDhCHsAAAxH2AMAYDjCHgAAwxH2AAAYjrAHAMBwhD0AAIYj7AEAMBxhDwCA4Qh7AAAMR9gD\nAGA4P0+erLy8XElJSfruu+/k6+urWbNmqUuXLlW2eeutt7R69Wr5+Pho7Nixio2NVUVFhf70pz/p\n0KFDOn36tB5//HENGDDAk6UDAOC1PHpl/8477ygoKEjp6em699579cILL1QZLysrU2pqqlatWqW0\ntDStXr1ahYWFevPNN9WmTRulp6drxowZmj17tifLBgDAq3k07LOzsxUTEyNJGjx4sHJycqqM5+bm\nqm/fvrJarWrdurUiIyOVk5OjW265RVOnTpUk2Ww2FRYWerJsAAC8mken8Z1Op2w2myTJx8dHFotF\np06dUkBAwDnj0tlgdzgc8vf3r1y3evVq3XzzzZ4sGwAAr9ZoYb9+/XqtX7++yrrc3Nwqyy6Xq8Zj\n/Of4mjVrlJeXp8WLF9d6/uDgQPn5+daxWnOEhFibugSvRw/dRw/dRw/dRw9/1mhhHxsbq9jY2Crr\nkpKS5HA41KtXL5WXl8vlclVe1UuS3W6X0+msXD527JgiIiIknf3ysGXLFi1atKjKlf75FBSUNdAn\n8R4hIVY5HMVNXYZXo4fuo4fuo4fua4k9rOnLjUfv2UdFRem9996TJGVlZWnQoEFVxvv166e9e/eq\nqKhIpaWlysnJ0YABA5Sfn6+1a9fqpZdeUqtWrTxZMgAAXs+j9+xHjBih7du3a9y4cQoICKj8q/ql\nS5dq4MCB6t+/vxITEzVx4kRZLBZNnjxZVqtVy5YtU2FhoRISEiqPtWLFiiqzAgAAoHoWV203zr1U\nS5u+kVrmtFVDo4fuo4fuo4fua4k9bDbT+AAAwPMIewAADEfYAwBgOMIeAADDEfYAABiOsAcAwHCE\nPQAAhiPsAQAwHGEPAIDhCHsAAAxH2AMAYDjCHgAAwxH2AAAYjrAHAMBwhD0AAIYj7AEAMBxhDwCA\n4Qh7AAAMR9gDAGA4wh4AAMMR9gAAGI6wBwDAcIQ9AACGI+wBADAcYQ8AgOEIewAADEfYAwBgOMIe\nAADDEfYAABiOsAcAwHCEPQAAhiPsAQAwHGEPAIDhCHsAAAxH2AMAYDjCHgAAwxH2AAAYjrAHAMBw\nhD0AAIYj7AEAMBxhDwCA4Qh7AAAMR9gDAGA4wh4AAMMR9gAAGM6jYV9eXq7ExESNGzdO48ePV35+\n/jnbvPXWWxo9erRiY2O1fv36KmNOp1MDBw7Ujh07PFUyAABez6Nh/8477ygoKEjp6em699579cIL\nL1QZLysrU2pqqlatWqW0tDStXr1ahYWFleNz585Vly5dPFkyAABez6Nhn52drZiYGEnS4MGDlZOT\nU2U8NzdXffv2ldVqVevWrRUZGVm5TXZ2ti666CL16NHDkyUDAOD1PBr2TqdTNpvt7Il9fGSxWHTq\n1KlqxyXJZrPJ4XDo1KlTSk1N1ZQpUzxZLgAARvBrrAOvX7/+nHvuubm5VZZdLleNx/hpfOnSpYqN\njVVQUFCdzx8cHCg/P986b2+KkBBrU5fg9eih++ih++ih++jhzxot7GNjYxUbG1tlXVJSkhwOh3r1\n6qXy8nK5XC4FBARUjtvtdjmdzsrlY8eOKSIiQq+//rrOnDmjNWvW6NChQ9qzZ48WLFig7t27n/f8\nBQVlDf+hmrmQEKscjuKmLsOr0UP30UP30UP3tcQe1vTlxqPT+FFRUXrvvfckSVlZWRo0aFCV8X79\n+mnv3r0qKipSaWmpcnJyNGDAAK1du1br1q3TunXrNHToUKWkpNQY9AAA4GeNdmVfnREjRmj79u0a\nN26cAgICNHv2bElnp+kHDhyo/v37KzExURMnTpTFYtHkyZNltTINAwCAOyyu2m6ce6mWNn0jtcxp\nq4ZGD91HD91HD93XEnvYbKbxAQCA5xH2AAAYjrAHAMBwhD0AAIYj7AEAMBxhDwCA4Qh7AAAMR9gD\nAGA4wh4AAMMR9gAAGI6wBwDAcIQ9AACGI+wBADAcYQ8AgOEIewAADEfYAwBgOMIeAADDEfYAABiO\nsAcAwHCEPQAAhiPsAQAwHGEPAIDhCHsAAAxH2AMAYDjCHgAAwxH2AAAYjrAHAMBwhD0AAIYj7AEA\nMBxhDwCA4Qh7AAAMR9gDAGA4wh4AAMMR9gAAGI6wBwDAcIQ9AACGs7hcLldTFwEAABoPV/YAABiO\nsAcAwHCEPQAAhiPsAQAwHGEPAIDhCHsAAAxH2HuR8vJyJSYmaty4cRo/frzy8/PP2eatt97S6NGj\nFRsbq/Xr11cZczqdGjhwoHbs2OGpkpud+vawoqJCTzzxhMaNG6exY8dq165dni69WZg5c6bi4uIU\nHx+vPXv2VBnbvn27xowZo7i4OKWmptZpn5aqPn2cO3eu4uLiNHr0aP3tb3/zdMnNTn16KEknT55U\ndHS0MjMzPVlu03PBa2RmZrqmTZvmcrlcrm3btrkeeuihKuOlpaWuYcOGuYqKilwnTpxwjRw50lVQ\nUFA5/thjj7lGjRrl+vjjjz1ad3NS3x5u2LDBlZKS4nK5XK4vv/zSNXr0aE+X3uR27NjhSkhIcLlc\nLtf+/ftdY8eOrTJ+0003ub777jvX6dOnXePGjXN99dVXte7TEtWnj9nZ2a67777b5XK5XD/88INr\nyJAhni67WalPD38yb94812233ebauHGjR2tualzZe5Hs7GzFxMRIkgYPHqycnJwq47m5uerbt6+s\nVqtat26tyMjIym2ys7N10UUXqUePHh6vuzmpbw9vueUWTZ06VZJks9lUWFjo8dqbWnZ2tqKjoyVJ\nXbt21fHjx1VSUiJJys/PV7t27RQaGiofHx8NGTJE2dnZNe7TUtWnjwMHDtSCBQskSUFBQTpx4oRO\nnz7dZJ+hqdWnh5J04MAB7d+/X0OHDm2q0psMYe9FnE6nbDabJMnHx0cWi0WnTp2qdlw6G0oOh0On\nTp1SamqqpkyZ4vGam5v69tDf31+tWrWSJK1evVo333yzZwtvBpxOp4KDgyuXf+qNJDkcjmr7VtM+\nLVV9+ujr66vAwEBJ0oYNG3TdddfJ19fXs4U3I/XpoSTNmTNHSUlJni22mfBr6gJQvfXr159zzz03\nN7fKsquWJx3/NL506VLFxsYqKCioYYts5hqyhz9Zs2aN8vLytHjx4oYp0ovV1ruG2sd0F9KTzZs3\na8OGDVq5cmUjVuR96tLDN954QxEREerSpYsHKmp+CPtmKjY2VrGxsVXWJSUlyeFwqFevXiovL5fL\n5VJAQEDluN1ul9PprFw+duyYIiIi9Prrr+vMmTNas2aNDh06pD179mjBggXq3r27xz5PU2jIHkpn\nvzxs2bJFixYtkr+/v2c+RDNSXW9CQkKqHTt69Kjsdrv8/f3Pu09LVZ8+StK2bdu0ePFiLV++XFar\n1bNFNzP16eHWrVuVn5+vrVu36siRIwoICFDHjh01ePBgj9ffFJjG9yJRUVF67733JElZWVkaNGhQ\nlfF+/fpp7969KioqUmlpqXJycjRgwACtXbtW69at07p16zR06FClpKQYH/TnU98e5ufna+3atXrp\npZcqp/NbmqioKL3//vuSpLy8PNntdrVt21aS1LlzZ5WUlOjw4cOqqKhQVlaWoqKiatynpapPH4uL\nizV37lwtWbJE7du3b8rym4X69HD+/PnauHGj1q1bp9jYWE2aNKnFBL3Elb1XGTFihLZv365x48Yp\nICBAs2fPlnR2mn7gwIHq37+/EhMTNXHiRFksFk2ePLnFXwH8p/r2cNmyZSosLFRCQkLlsVasWFFl\nVsB0kZGR6tOnj+Lj42WxWJSSkqLMzExZrVbFxMRo2rRpSkxMlHS2z+Hh4QoPDz9nn5auPn3MyMhQ\nQUGBHn744crjzJkzR2FhYU31MZpUfXrY0vGKWwAADMc0PgAAhiPsAQAwHGEPAIDhCHsAAAxH2AMA\nYDh+egfgHIcPH9bw4cPVv3//KuuHDBmiu+++2+3j79ixQ/Pnz1d6errbxwJQO8IeQLVsNpvS0tKa\nugwADYCwB3BBevfurUmTJmmaBeZnAAAB80lEQVTHjh0qLS3V7Nmz1aNHD+Xm5mr27Nny8/OTxWLR\n008/rW7duumbb75RcnKyzpw5o1atWmnWrFmSpDNnziglJUWfffaZAgICtGTJEl100UVN/OkAM3HP\nHsAFOX36tLp37660tDSNGzdOL774oiTp8ccf19SpU5WWlqY777xTzzzzjCQpJSVFEydO1Jo1azR6\n9Ght2rRJ0tnXjT7wwANat26d/Pz89M9//rPJPhNgOq7sAVTrhx9+0IQJE6qse+yxxyRJ1157raSz\njy1dsWKFioqK9P333+vKK6+UJF199dV65JFHJEl79uzR1VdfLUkaOXKkpLP37C+77DJ16NBBktSx\nY0cVFRU1/ocCWijCHkC1arpn/8unbFssFlkslvOOS2en7P9TS34fO+BpTOMDuGAff/yxJGn37t3q\n2bOnrFarQkJClJubK0nKzs6ufDVwZGSktm3bJkl69913NW/evKYpGmjBuLIHUK3qpvE7d+4sSdq3\nb5/S09N1/PhxzZkzR9LZt7DNnj1bvr6+8vHx0bRp0yRJycnJSk5O1muvvSY/Pz/NnDlThw4d8uhn\nAVo63noH4IL07NlTeXl58vPjWgHwFkzjAwBgOK7sAQAwHFf2AAAYjrAHAMBwhD0AAIYj7AEAMBxh\nDwCA4Qh7AAAM93+XgqMyE7b4+gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "5s6xCHIf2ly7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Visualization of the results"
      ]
    },
    {
      "metadata": {
        "id": "XFA_8uN4Eb3B",
        "colab_type": "code",
        "outputId": "9c20c238-33e5-4f99-cc49-bebfcf765935",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "cell_type": "code",
      "source": [
        "plot_denoise(denoise_model)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  1.68it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAACmCAYAAABXw78OAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKYQQQgRAE6YQQggRAE2YQgghRAD+H8XxUNQK8f5DAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "SyABaCvkEPDR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training a Descriptor Network\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "bb021b54-69ae-4e37-d6cf-2344c9d5a27d",
        "id": "H2YMSING3F1Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Lambda\n",
        "shape = (32, 32, 1)\n",
        "xa = Input(shape=shape, name='a')\n",
        "xp = Input(shape=shape, name='p')\n",
        "xn = Input(shape=shape, name='n')\n",
        "descriptor_model = create_model()\n",
        "\n",
        "# Uncomment these lines to train the baseline descriptor model\n",
        "# descriptor_model = get_descriptor_model(shape)\n",
        "\n",
        "ea = descriptor_model(xa)\n",
        "ep = descriptor_model(xp)\n",
        "en = descriptor_model(xn)\n",
        "\n",
        "loss = Lambda(triplet_loss)([ea, ep, en])\n",
        "\n",
        "descriptor_model_trip = Model(inputs=[xa, xp, xn], outputs=loss)\n",
        "descriptor_model_trip.compile(loss='mean_absolute_error', optimizer='adam')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YIR1cH4fDwKj",
        "colab_type": "code",
        "outputId": "d8af1994-574f-4ac8-9ab8-f28b087e3787",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        }
      },
      "cell_type": "code",
      "source": [
        "### Descriptor loading and training with CLEAN patches\n",
        "# Loading images\n",
        "hPatches = HPatches(train_fnames=train_fnames, test_fnames=test_fnames,\n",
        "                    denoise_model=None, use_clean=True)\n",
        "# Creating training generator\n",
        "training_generator = DataGeneratorDesc(*hPatches.read_image_file(hpatches_dir, train=1), num_triplets=100000)\n",
        "# Creating validation generator\n",
        "val_generator = DataGeneratorDesc(*hPatches.read_image_file(hpatches_dir, train=0), num_triplets=10000)\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using clean patches\n",
            "100%|██████████| 116/116 [00:31<00:00,  3.87it/s]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100000/100000 [00:01<00:00, 64267.72it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using clean patches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 116/116 [00:19<00:00,  5.97it/s]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:00<00:00, 60284.90it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "GoQYyuD7_4PS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We plot a random triplet in the form of anchor, positive and negative sample. The positive and anchor patches are similar between them (the difference is a geometric transformation, for example rotation), whereas the negative sample should be quite dissimilar to any of the other two."
      ]
    },
    {
      "metadata": {
        "id": "3RQmOMU92csu",
        "colab_type": "code",
        "outputId": "6769af1f-1bfe-4187-e1f5-866dae09e545",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        }
      },
      "cell_type": "code",
      "source": [
        "plot_triplet(training_generator)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAACmCAYAAABXw78OAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi40LCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcv7US4rQAAIABJREFUeJztnXmUFcXZxh92MQgIsonIpndGZHHY\nJvIJGEMUFBC3yCYi4oJxjoIRE0FBwQVN9KDgQT3GuCTKLhI3VFAxYgQMQT2iyKAwwgAOuwgi9PeH\n516nny7uWz2r4PM7Z/6ovtXV1VXVXdP11Pu+FYIgCCCEEEKItFQs7woIIYQQhwOaMIUQQggPNGEK\nIYQQHmjCFEIIITzQhCmEEEJ4oAlTCCGE8EATZgzy8vKQkZGB22+/vbyrIo5wkmPtT3/6U4nkE6I0\n+aWMw8N2wpw0aRIyMjLQsWNH7N27t7yrI44g5syZg4yMjMjfKaecgi5duuAPf/gDli1bVqp1qFu3\nLiZPnoxBgwaFjj/yyCPIy8sz84mfN8kx1rZtW6xfv/6Q+c466yxcdtllZVgzP36p47ByeVegKHz/\n/feYO3cuKlasiF27duHVV19Fv379yrta4gijT58+6NGjRyq9d+9e5ObmYvr06Vi4cCEmTZqEvn37\nlsq1q1evjp49e4aOrV+/HpMnT0aHDh1wwgknHDKfOHzYt28fJkyYgMcee6y8q+LNL3kcHpZfmAsW\nLMC2bdvQv39/VKhQATNmzCjvKokjkEQigZ49e6b++vXrh1GjRmHWrFmoXr067rrrLuzfv7/M6vPR\nRx+V2bVE2ZCdnY23334bCxYsKO+qePNLHoeH5YQ5ffp0AMDll1+ODh06YPny5VizZk0oz3/+8x9k\nZGTgkUcewfLlyzFo0CBkZWUhKysLw4cPdy6DvPzyy+jfv38q3zXXXINPPvnEWYfVq1dj2LBhaN++\nPbKysnDllVdi3bp1kXwvvvhiqsw2bdqgZ8+eePDBB7Fnz55QvoyMDAwdOhSLFy/GOeecg//7v/8r\navOIUqZJkybo3Lkztm/fjtWrVwP48UthypQpOPfcc9G2bVtkZWXhkksuwcyZMyPnf/DBB7j66qvR\ntWtXtGnTBt26dcPIkSPx+eefp/KwJnTZZZdh5MiRAIAhQ4YgIyMDeXl5kXwDBw5EZmYmNm3aFLlu\nfn4+MjMzQ8tmW7duxcSJE3HWWWehdevWyM7OxogRI/C///2v5BpMHJKrrroKTZs2xV133RV5JxyK\nWbNm4eKLL0a7du2QlZWFCy64AM888wwOHjwYyrd7925MmDABZ5xxBtq2bYuLL74Y//73vzFz5kxk\nZGRgzpw5ofwvv/wyBg0ahPbt26NNmzY455xzMGnSJOzcuTOV55c+Dg+7CXPt2rX44IMPkJWVhWbN\nmqWWYl0vJgD47LPPcP3116NTp064/fbbcd5552Hx4sXIyckJ5XviiScwcuRI1K5dG+PGjcPIkSOx\nevVqDBgwACtXrgzlLSgowDXXXIM2bdpg/Pjx6NOnD959912MHj06lG/q1Km4+eabEQQBbrjhBtx+\n++047bTTMG3aNFx99dWRAb53717ccccdGDhwIG699dbiNpUoRY466igAwA8//ICDBw/i2muvxcMP\nP4zMzEyMHTsWN910E6pVq4axY8fiwQcfTJ334YcfYujQocjLy8Pw4cNx9913Y+DAgVi6dCkGDRqE\nDRs2OK+Xk5OTWvLKycnB5MmTUbdu3Ui+8847D0EQ4PXXX4/89uqrryIIgtQy8o4dO9C/f3+88MIL\n6NWrFyZOnIgrr7wSq1atwqBBg7BkyZJit5NIT9WqVXHbbbchPz8fDz/8sJn/3nvvxZgxY1C/fn2M\nHTsWo0ePRr169TBx4kTcdtttobx//OMf8eyzz6Jt27YYO3YsunbtilGjRuG9996LlPv8889j5MiR\nOHDgAG655RZMmDABXbp0wd///ndcccUVqXfVL34cBocZ9957b5BIJIIZM2YEQRAEu3btCtq1axdk\nZ2cH+/btS+V7//33g0QiEWRkZAQrVqwIlTFkyJAgkUgE69atC4IgCAoKCoJTTz01GDx4cHDw4MFU\nvjVr1gQZGRnBsGHDgiAIgvXr16fKXLZsWajMYcOGBYlEItiwYUMQBEGQn58ftGrVKujdu3eoXkEQ\nBOPHjw8SiUTw0ksvpY4ly503b15xm0gUk9mzZweJRCJ49NFHnb/v2bMn6Nq1a9C2bdtgz549wUsv\nvRQkEongtttuC+Xbv39/0Ldv3+CUU04J8vPzgyAIggkTJgSJRCJYuXJlKO+nn34aDB06NHj77beD\nIPhprN1yyy2pPA899FCQSCSC999/P3WM8xUUFAStWrUKBg8eHKn3pZdeGrRu3TrYvn17EARBcPfd\ndweZmZmR5yM/Pz/o0KFD0KdPH6/2EvFJjrFkX+bk5AStWrUKPvvss1C+3/zmN6m+/PTTT4NEIhGM\nHz8+Ul5OTk6QSCSCTz75JAiCIPj444+DRCIRDBo0KJRv6dKlQUZGRpBIJILZs2enjk+aNCkYMGBA\nsGvXrlD+kSNHBolEIli6dGnq2C95HB5WX5jJzT7Vq1dHr169AAA1atTA2WefjW3btuGNN96InNO+\nfXu0a9cudKxNmzYAgM2bNwMAXn/9dezfvx99+/ZFhQoVUvlatGiB5557Dn/+859D57du3RodOnQI\nHcvIyAiVuXDhQvzwww+46KKLULVq1VDeiy66CACwaNGi0PFKlSqFNpmI8mXfvn3YuXNn6m/Lli1Y\nunQprr32WmzatAlXXXUVqlevnvovun///qHzK1eujPPPPx8HDhzAO++8kzoGAMuXLw/lzczMxJNP\nPolu3boVq8516tTB6aefjuXLl6OgoCB1PD8/HytWrED37t1Rq1YtAD8uwbVs2RLNmzcP3Wf16tXR\nsWNHfPbZZ9ixY0ex6iP8uPXWW1G1alXccccdCA4RQOqVV14BAJx77rmh/tq5cyfOOeccAD8u9wM/\nSlIA0Lt371AZHTt2RPv27SNljx49Gv/85z9Ro0YNHDx4ELt27cLOnTtx4oknAgC+/vrrWPdzpI7D\nw2qXbHKzT9++fVGjRo3U8QsvvBDz5s3DjBkzcO6554bOSXZ4YapVqwbgx+U0ACkdqkmTJpG8WVlZ\nkWNNmzaNHKtevToApExccnNzAQAnn3xyJG/z5s0BAF9++WXoeJ06dXD00UdH8ovyYcqUKZgyZUrk\neO3atXHLLbfgiiuuAPBTX5900kmRvNzXAwYMwLx583DPPfdg3rx56NatG7p06YIOHTqkJtPi0rt3\nbyxevBhvvPEGLr30UgDRZbBdu3Zh8+bN2Lx5Mzp16nTIsjZu3Jh6sYnSo2HDhrj++utx3333Ye7c\nubjwwgsjeb744gsAwODBgw9ZTnJJPznBud5V7dq1i/zDtnv3bkydOhULFixAfn5+6t2Y5MCBA/Fu\nCEfmODysJszkZp/OnTvjq6++Sh1v2LAhjjvuOLz//vtYv359aOLjrzsXyUmuSpUqXvXwyZcU8JMT\naWGS+td3330XOv6rX/3K6/qibPj9738f+g+9YsWKqF27Nlq0aIFKlSqlju/ZswdVqlRxjjXu66ZN\nm2Lu3Ll44okn8Nprr2HatGmYNm0a6tati5ycHAwYMKDY9e7RoweqVauGBQsWhF5UNWvWxJlnngkA\n+PbbbwH8+GWbTi9v3Lhxsesj/Lj88ssxd+5c3H///fjtb38bmSCSffbAAw/guOOOc5ZRr149AD+N\nt+T4K8wxxxwTSgdBgGuuuQbLli3DGWecgZycHNSvXx+VKlXCv/71ryJbIRyJ4/CwmTBzc3NTyw1j\nx449ZL5Zs2aldnH5khStd+3aVfQKEskvRdfOt+Rg1gT586ZJkybIzs428x199NHYv38/vv/++8ik\nmez/wn3dsGFDjBkzBmPGjMGqVauwaNEiPPvssxg/fjyOPvponH/++cWqd40aNXDmmWdi4cKF2LFj\nB7777jusWLECl1xySap+yfrs37/f6x5F6VO5cmWMGzcOgwcPxl//+lfceeedod+TfdakSRO0bds2\nbVnJft63b1/kt927d4fSK1euxLJly9C5c2c8/vjjqFjxJ6Xu3XffLdK9AEfmODxsNMzkfzmXXHIJ\nJk+eHPm77777UKlSJcyePTuynGCR/O8luTRbmDfffBMvvvhi7Poml+cKmwokSS6ttGjRIna54udH\nur5Omju1bNnSeW5mZiZGjBiBJ554AgBKzB6vT58+2L9/P956663IMhjw41dGgwYN8NVXX4U0piRb\nt24tkXqIeHTq1An9+vXDzJkzI7vzk+Psww8/jJz37bffhibHBg0aAIBz1zWbaiQ99mRnZ4cmSwBY\nunRpEe7iJ460cXhYTJjJzT5Vq1bFqFGjQsbkyb/zzz8fPXr0wJYtW/DWW2/FKr979+6oUqUKXnjh\nhZAh+qZNm3DDDTdg1qxZset81llnoUqVKpg9eza+//770G/JpeWkUC8Ob5Lb7J9//vnQ8eS4rVat\nGrp37w4AuPrqq0Pb9JMkNfl0EkLyZeb6amC6d++OY445Bu+88w7efPNNNG7cGB07dgzl6dWrF374\n4Qc8/fTToeM7duxAv379MHz4cPM6ouQZPXo0atSogXHjxoW0w+RGx+eeey7iDvT+++/Hr3/965Qt\neHLvRXKjUJJly5ZFJtzkChtv7JkzZ05Kny98vV/yODwslmRfe+01bN++HRdeeCHq1KlzyHyDBw/G\na6+9hpkzZ2LYsGHe5Tdo0ADXXXcdJk+ejCuuuAIXXHAB9uzZg2eeeQYAIvaVPtSrVw833ngj7r//\nfgwZMgR9+vRBlSpVsGTJErz88ss4++yzU+v44vCmR48eOPPMMzFz5kzs27cP2dnZ+Pbbb/HSSy8h\nNzcXY8aMwbHHHgvgR/09OSZ69eqFWrVq4ZtvvsGMGTNQuXLlyE7bwiTdkE2bNg1r1qxBt27dUhvY\nmKpVq+J3v/sdFi5ciN27d+PKK68M7QAHgBEjRuDNN9/Eo48+ioKCAnTq1AkFBQV4/vnnUVBQgCFD\nhpRQC4k41K1bFzfeeGNqSTa5cTEzMxOXX345nnrqKQwYMACXXnopKleunPIU1Ldv31Te7OxstG7d\nGu+88w5uuukmdOnSBV9//TVmzJiB8847D/Pnz09dLysrC40aNcL8+fPRoEEDNG/eHB988AGWLFmC\ncePGYdSoUZg7dy6OPfZY9OrV6xc9Dg+LCbOwZ590dO7cGYlEAosXL47slrW47rrr0KhRIzzzzDO4\n8847UbFiRXTo0AEPPfQQMjMzi1Tv4cOHo1GjRnjqqafwl7/8BQcOHEDTpk1x8803Y+jQoUUqU/z8\nqFChAh5++GE8/vjjmD9/Pl555RVUrVoVrVq1wtSpU0OmQsOHD0f9+vUxffp0PPTQQ9i9ezdq1qyJ\n0047DRMnTnRu+U/Ss2dPvPLKK3jvvfeQm5uLNm3aoGHDhofM37t375Q3F5fP29q1a2PGjBmYOnUq\nFi1ahBdeeAHVq1dHu3btMHHiRHTu3LkYrSKKw4ABAzBnzhx8/PHHoeO33norTj75ZEyfPh333HMP\nDh48iGbNmkXeKRUqVMC0adNw99134+2338aiRYvQunVrTJkyJWVykvxSrFatGh599FFMnDgRTz/9\nNI466iicfvrp+Mc//oH69etj/vz5eO+99zBt2jT06tXrFz0OKwSHMvoRQghxxHHvvffiySefxGOP\nPZaSCoQfh4WGKYQQwp+9e/fipptuijhd2bdvH1599VVUqVIl5cBF+HNYLMkKIYTwJ2l/OWfOHOzY\nsQM9evTA3r17MWvWLGzcuBHDhw9Pux9EuNGSrBBCHIHs378ff/vb3zBv3jxs3LgRBw8eRIsWLXDx\nxRdj4MCBkc03wkYTphBCCOGBNEwhhBDCg7Qa5ogRI0Jp9ovKfgrZcbjLLRwb3LJzdP7gTfoaTMLu\n5NgpADsJdnn94S3QltPrmjVrhtKHsjlKUtjPLQBnMGi+j+OPPz6ULuxcHkDEWz87bn/88cdDaQ6Q\nnTRALgz3DxvTs7/K4nr98IUdT7PvXvZGwr+7lpp4XHGaxwmPO/ZCsn379rT5XeOOx1nSNjMJP0+c\nn8c6G45zHbg/gWjbcZ5ktJ0k/DxxWxf2qeuqY1Hg98yWLVuKXaaFK0hCYbhvOM3+WYEfzSUKY71n\nuEx+B1h1cJWfn58fSn/zzTehdLNmzUJpfva4Dv/9739DafaOxu93V704zc8K/87jwWpH9tHtqpfl\nDe6BBx5wHtcXphBCCOGBJkwhhBDCg7Tftuz8l5fo6tevH0q7liUYXkbgpTFeAuIlJGtnF/vidNWJ\nl1T585yXnaxYcFwnXsLlZRFXPXk5m+tY2MctEF124EgrmzZtCqV5CRH4yYdkEl7q4GuWFdznPEa4\nvTnt2sfGfWwt0XL7N2rUKJTm/uKlTF4eBaLjiJcveXnTWvbjZSZuB9fyKC/B8rjhduC+4DryPfn0\nBdeBy3SFxCtreLzEDehQFKyly7hLm65jlizAMV05/0cffVTsOvAyb0nft09fucKe+aAvTCGEEMID\nTZhCCCGEB5owhRBCCA/Sapg7d+5Mm2Ztjl0tNWnSJFImm1O4goYWhteaWSNhDYXNL3hrNwDUqlUr\nbRmsX7HGYpkksLkGb+V2XYP1JtYoWRNjTZI1S04nA8qmK4M1MtaoywrWzVizsEwjXBqGpXuyHshl\nsq7NOgyPER6HQFQvZLMQvi/W8rhO/Cz5tAMf4/u2xjo/K3xNTrv2HFg6Z3lo5y5ziHS/F1UDS1cG\np/malnbnugfOY5m6cBlsduJ6n1pYmiLXgZ81y4ykKPoyn7N7926v8/SFKYQQQnigCVMIIYTwQBOm\nEEII4UGs8F6sNbBWx+vfbI8IRO18LFd4vLbM+S1tyWUHxloR6zKs47Dmwuez5sJ15vIA2/aTNTDW\nv/Ly8kJpdsfH6/4uu0B2Ech5Nm7cGDmnPOA+ZJ3M+h2I9iG3D5/Dfcp6I9vRsibN9m1AVKNiDZmf\nH+5zy56NxxDbigLRPrZsjLlMSye1tGIffPWkksRynWbpiyWhuxZXq3P9bumkjOU6z3Jb5+o7675K\nGh/tXhqmEEIIUYpowhRCCCE80IQphBBCeFCsxWUr9rQrDJZlQ2etifPaM+s0bJvGNpeA7ZuUdR3r\nPvmeuA6uNXVLh2P7VG4HDu/Fmkrjxo1DaZeGyddgf6msoZUVfF3WXSyN2aUZMy6dszA8Brj9eNxZ\nmhcQ1fR5rLNuzXsEuF2sZ4fHpauecW3YrHZjXBoma1rcX66xWtpY7xnGpx25zLjhuqwxxf1dlNBa\nnN62bVsovWLFilCadXfLV62LuGPOKpP1Y5/yfWxYXegLUwghhPBAE6YQQgjhgSZMIYQQwgNNmEII\nIYQHadVUNlrdsmVLKG05B2aR2wVvdmEn5KtWrUp7Td7cwmmXmGsFMOXNGa7NE4XhdmHH6Wz87boG\ntwMHJOYNH2xgzPfEdXI5wudNP+vXrw+lmzZtGjmnLGCHCezwmTc7WM7yXfA4i+u4gLEcALjqxZs4\nuA950wj3F9eJ78nluIDP4U05rnMKw+1iBft2bRLia7ATiJ+j83XGZ9OPtSHG2gTE53NwBH4n+NyD\nVW8OqMHvGf69KBtuLEf2nLbep5bTCcDe7HTcccelqfFP6AtTCCGE8EATphBCCOGBJkwhhBDCg7Qa\nZps2bUJpXitmnYw1FlewUV6fZt2FjbV5/ZoNZ9nY++uvvw6ljz/++EgdWJu1NDBe32bNhQNrW/oi\nEG0brjc7Jti6dWso/fnnn4fSrAvxPbFzdsB28sB6RVnB98o6CQfDZk3TcjQBRLU17nPuY+5D1v64\nzjxugehYZ02Kx0TdunVDae4vHmesebocAFgO3Pn55LHN5/M98e+uvrB0VL7P8iCuw3CXbuYaA4Xh\ntrf2hFj7GHz0Qy7Ter9aBv5F0U2t3612sDRLn77jPL4BwfWFKYQQQnigCVMIIYTwQBOmEEII4UHa\nxV7WZVgnY9s+tttzaRGss7BNDWsinLZsIlnTdOk4GzZsCKWt+7B0H7ap5PJzc3MjdWDNjO0uWZ/g\nNNv9sfbAGpxrjZ61JNYCfW2TShtuf247yxm765ilc1jBmFn78akD9wlrMZaDd9Y4eRyyxsV7DICo\nJsm6NWvfVvB0Lo81Sx8Nk/vXtfehtInrpJxxaXmWNsfPdNwA0vzM+2h3VtDxuI7Ri0Lc+7Q0zbIM\nUK0vTCGEEMIDTZhCCCGEB5owhRBCCA/SLv7y+jbrj2wzWb9+ffOCbFNnrT+zpmL5AGXNxeXLkrUe\nth+1Aiuzxsn6FdsvugIxs3bEbcl61po1a0JpXuevU6dOKM2aqEsXqlevXijt0rzKA9a9WDdjPdbl\nq9eC+8wKKs7jkMct94dLw2T9iPuI2//YY49NWybvEeD+dPmF3bRpUyjN+rv1/PB9c37eQ+DqG34e\nuO18/PKWNMXVxVhPBKLjlN+ffE7cgNKWHaeLuDaR1u/FDUjuQ1HsLK0yioq+MIUQQggPNGEKIYQQ\nHmjCFEIIITxIuxjMGgrrh6yzWdoTENWCOA/roF27dg2lOWZjXl5eKG3pI4Ad/5Jt7NivK6dZH7R8\nhgJRzZL1LNaCGNZD+J5YZ922bVukDL4m61E/F02TtTjL76NL4+CxyTqZFUOTxynbVLLfV9e442ty\nGTzuuM/4fE7zOORnDYjq8exrmW2v+XniMlmjtOKGAtG2LIoGXdpYmib3Lz+PLuLGjoxrn+rSUS2N\n0bW/ojBcZ75P6z3kOhbXDtPXz2tx8NU49YUphBBCeKAJUwghhPBAE6YQQgjhQdrFZNZUWNNkPYN9\nkbps0Sz7N9Z12LaM04lEIpTmuJKuOJCWv9mGDRuG0hw/k23ZWLNk+zjWE4GoH0luB9avWCtgPYN/\nZ33SpaMyrGc0btzYPKc04HHD44o1ME77xMOMWwdLn+dxa/k8BuzYkdaeAbaRtGwmgajf5MzMzFB6\n7dq1oTS/A1g3ZY2LNUyXpsnvALYn5P4uC+La9vnEU7TshS27S24X1p99tMG48S0Z/t1Hs2QsfbC4\nNrA+dpol5W9WX5hCCCGEB5owhRBCCA80YQohhBAepF3YXbJkSSjN+iFrfRw/0eXLkolrg2WtRZ9w\nwglp00DU1oztKlmjZD+tbHPHug7HCHS1A98H68GsiTF8D6xvsN7lsrdiHZTrxPdRVlj6IKctG0vA\ntrNkWMO04kL62HXyOdz+rH1zH3KaNU7WC117CFjL5n0JrFFZY5u1ctaTuI5A9HngtnL5fy5vLHtG\nHw2TNUnr+eP3Lb9ffXQ51iCLq1kyJaFhcrvE9VdbFA2zqL5l9YUphBBCeKAJUwghhPBAE6YQQgjh\nQdoFaCue24oVK0Jptp9y6Yd8jPVBy8aO4bVo1lRcWiBrB+3btw+leR2fbTnZ1pPb6eSTTw6lGzRo\nEKkD6zRsd8kxOS07StZd2d7OZQ/H9qisoXHflBWsa7O+a9lIuojrO9bSMK24kC4dztJmub25ztzH\nrGmyNujaH9C8efNQmn3J8rjjuK1cJo8Zfge4NDN+ZtmWM67eXBrE9fPq0s34PcMapFUmv1d4zwjj\n8iVrURL3aZVn3RePGct/bWnga6epL0whhBDCA02YQgghhAeaMIUQQggPNGEKIYQQHsQKIM0CPjsQ\n56DIrqDFa9asCaV5Q8ypp54aSrPxLgvIvNGBg0G7AjGvW7culOaNDbz5Ijs7O5Rmh9S8Cahbt26h\nNIvYQHQDyKpVq0Jp3vjAbcuO0dn4lzdvuJwn8KYEvkZ5Bfa1nHFbm3xcG8V4Ew6X4TLyT/c7tw3/\n7jLYZ3ijAfc5b45ghxncTjzOXJu2TjrppFCaxxEHZOcyuc5cB0672oHHGb9XfBzX/9zg+wZsZ+m8\nmcXaYMMb+fj9y2nAdr7u40Q+3fk+ztwtBw7W71aw7qI4T5DjAiGEEKIU0YQphBBCeKAJUwghhPAg\n7eIvrxWzA28rgK1LF2Jja9b/WrRoEUpbWhEbf7PuytcDokb8vM6/evXqUJp1UdZdW7ZsGUqzIwS+\nRyC61s8O4HmNnR0+sLbExv1skO7SN3jtnwNdb9myJXJOWcC6Nfexy7l6YVwap+XQ23KmzrCObQWY\ndh2znMa7tO/CcJ/zs+LS1VgvimtUzljO2l114DysaVr3/XPACu4MRPcIcFvze4efce4Lfmds3Lgx\nlHY9r3EDRlv5Xf1pwffBTlgsJ/RxHcK7dFguQxqmEEIIUYpowhRCCCE80IQphBBCeJBWw2T7RNb+\neK3Yx/aMYd2F17ctWzXWNPl31h9d5/A1eZ2enV5z2jqf2xGIOmJmG7sNGzaE0rxuz23Pegi3K+sE\nQNRRPZ9TXs7XuS2sAMM+AYcth+2sm/HvPA5Zj/QJgmzpnNyHXGfWE1mH4fJc9mmW7R/riexcnZ9x\nHkN8Dy7Ni9vK6ouygDUuyz7Rx7G6pRdz27B2z7+zZpmfnx+5JuPrVDyJZadppX0CaVttZ+nq1j25\nfrf6whd9YQohhBAeaMIUQgghPNCEKYQQQniQdjH4tNNOC6VZa+A19PXr14fSLrsg1kgsDZIprrYE\nRO3A2M8qa2jsb5PtUa0g2C4/rqyt8jn169cPpVnT5Guyj1DuG5ftUocOHUJp7hvWassKHhOWVmfZ\nM7rgccHnxNVJeRyyjSRgB0fnOrGmzL+z1meNISCqk7HmyBqlpWFu3bo1lGb7VFe7cRm8B6A8fMkW\nV7tz6WaWvscaJWt5cX3PuvTiuFpd3HZgfDRMridrmvzusurk4yc2rpZ7KPSFKYQQQnigCVMIIYTw\nQBOmEEII4UHahV2OXdmwYcO06ebNm4fSrG8AUZ2T7Z/i6hmsd1lxD33KYB3GignosvUsjEtT4/tm\njZL1X25r1gXYHq5169ZprwdE76Nz586htMv/bHnAfcgaBfefa8xYtn6WZsn52SaS6+DyoxzXX62l\n53MduU6sxQNRPZ5tq1l75Wvs3LkzbX72+8vPkisP66rlgRWD0fJFWhS7vuLaF1o+Wl1YOmhxNUzX\n7+zf2/KRa2mUcf3h+tTTV+OA0UzfAAALwUlEQVTUF6YQQgjhgSZMIYQQwgNNmEIIIYQHaRdurdiV\nrMmwhuJaUz/11FNDabY14zIsnYc1GM7v0jBZQ+E06zaWjsr36dKvGF6HZx2H255t1zh2JdvTffzx\nx2nzA3bsUNZBywpLo2B84rBaWjZrbTt27DDLLAzrjTymXPW0tFj+3dILWRvi/nWVwc+LZZ/KGia3\nK9ttuuww+Rj3t6vepQ3bQPLzVBRfpJY+aGmYlpZn2Te6ymC47S09sSh2mHFtILkO/Gzy75YmWpQ6\nHAp9YQohhBAeaMIUQgghPNCEKYQQQniQdmGXtTnWHljfyMvLC6Vdus+JJ54YSjdr1ixtmT5+QQuT\nm5sbSru0hpYtW4bS7OvV0kGt2Ik+vk1ZI2H7VPYDypoa5+e+Yn3rq6++itSBtSJOsw5aVljxEC3d\nzQXr0DyWWb8tKCgIpS3NirVBl/0h6yiWf1r+nfV6vm+uI+cHovfF9r6s/7B/YbbN5XFp2XG6rsFl\nuPTf0oZ1sLjpouiHlsbp8v+crg5FybNt27ZQ2tJNLU2T96D4nGPdt6Wr+lDU+JeMvjCFEEIIDzRh\nCiGEEB5owhRCCCE8SLsYzP5JWSdjm6tGjRqF0mw7CET1PdZIXOcUxooJuHbt2lCatSkgugbOelOt\nWrVCadYn2HaUYY3NdU9sz8Zaw7p160JpthNj37KsH3OMOdaKgaivYNYw+ZplBccbZf2R+4/HlEs7\nt3RnHic8Lq1xa/WnCyveJWuQnObnkfvcpQWzZmXZMbN+ZGmY/KzwswRE+4/7m9PlgWUjyXbT/Dy6\nsPTAuDaQlq7qOseqE78LrTrzGPapQ1HiWVrXSFc+YNtuypesEEIIUYJowhRCCCE80IQphBBCeKAJ\nUwghhPAgrdKZn58fSnNAaN4kwg4AeBMCEDVk5mvwRiI2hGWRmTcI+BhB88aF1atXh9LsNIDrxL/z\n5gvevOEyrGeDcb4vDvTLm1J4k0mTJk1CaTZQdxnS8zVWrlwZSpeHE2zANoZngZ772MeRgeXQmTdq\n8TWsoOOu4Om8ccjaIGNtZuLNUHzfrs1P3LZ8n7xRiPPzuOXnmR1y+Dgh4LEf11lJSRDXUTqnecMj\nEB1TvOGK3xtFcfBuwc8Kjzkr0AGPa2uTj2tDjnVfVnBuxtr85IMCSAshhBCliCZMIYQQwgNNmEII\nIYQHaRdurbVnDijNa9Euh8S81m/pNqyR8Bo6a3Ws9bmCWLNzX16nZy2InQiwbmoFJ3Y5OmAtiLXc\nE044IZRu3rx52vNZr+L83FdAtB24jI0bN0bOKQsspwGsa7Pu5qOB8Tk8di39kH/n813G91ZQcNZq\nGSv4M7cLa+2ArR9xu7Amyfn5mnzfvF8AiOqa7CCjpBxlx4GfBcuw3Ud34/sqrhPxuM7ZXcTV7izN\nsihaoDUG4zpwcL3jSwt9YQohhBAeaMIUQgghPNCEKYQQQniQdsGZ15JZT2RbM15Td63rs5Ni1oZY\n52GtiNfUWcvja7KtGhC1YbRgrYjraNn9uTQ1bqs6deqk/Z1tXDMyMkJpDhDNWlSDBg0idfjyyy9D\nadYGONh3WWHZxFmOlF39wWVYTv+5z3icWkECXPZtrJWznTLrf5YtIOuH7BCc7WyBqCZZt27dUNra\nE8DtxjbK/I7g/EC0f4rqCLs0serAzyfbWAK2fWBce0TLablrz4j1LMVta8sGsiQ0TMsBPGuWVrsA\n0XmD34++urm+MIUQQggPNGEKIYQQHmjCFEIIITxIu+DM+iDrGZxmnccVwJbtsnj9mm3NWANhGy6u\noxVcGIjW27IlY82FdVGuE+tfPu3A2k9mZmYozT492a6SA0SvX78+lP7iiy8idWD/s9wXLtvNsoDb\ngtvPGmd8PmBrmBxIma/B44qvYQViBqLjyApkzjoZa1SsWXKadXEg2ses7XCanxXWQPkeatasGUq7\n2sGygfXxBVzSxNXi+B7YjhqwdTHW4spCw4wbhDquT10XcfckWO3g8ottUVTNktEXphBCCOGBJkwh\nhBDCA02YQgghhAex4mGyHsHrwKw9sO4GRLUhXnfnNXHWRFiTZPsnjuHoWu9mbYhtFFnDtPQs1l0t\nfQuI3ifrohs2bAilW7ZsGUqzvRzbYbIvWldsRO5fl91eeRBXX+C2K4puxudYurUVR9KlW3Ofs17I\n+iDXybJP47HPzw4QHTdsR8nPhpXmZ4HtOtmfKmDHdnXZTpc2/B6ydDdOu3zmch62QbfyMzxm2Y7X\npbvG9fVq+fW1NEtX+ZYmaf1u+cy1+uZQxwqjeJhCCCFECaIJUwghhPBAE6YQQgjhQdqFW9ZpeB2Y\n9UQrRiAQ1Sv4GrxGzmVY/mrZtsmlLVh2PC7NsTBs78br36xfsWYDRGNNNm3aNJTm+2a/r6xRsu76\n+eefh9Ku2Ihsf5qXlxfJUx5YdpXc55b+6DrH8h3L+iLXgfNb+j4Q1RSt5yuuvSn3p0sL5GeU24rH\nPu9D4DJ5nLJ9q2vccdvyNXzimZY21nvIRzezfP9aMTYZ1iyt/R+HOpauDpatp1Ue6/CuMq14xFY7\n+MQijXuOjz0poC9MIYQQwgtNmEIIIYQHmjCFEEIID9JqmKyRsKbCeghrD66YgZZfQMuPJOs4vI7P\na+iueHwcW9LSafg+WIuwtCZX/E0+tnnz5lCa412yDpCbmxspszAcy5LtNAGgUaNGoTT7ll23bl3a\na5QWPCb43nmMWDFTgaiGwX3KfcjX4D61NEuXfsg6iaWDso9ivgb/zvq9yxaUtW5+PvhZiPt8WnFc\ngajtJ/u8dcWWLG2K6zPVZcdX3DifnJ/fdUWxw2Qs22ArP/dVUeww49pdx7WRdR3jOskOUwghhChB\nNGEKIYQQHmjCFEIIITyIt6hOsE7DaZf/UtZFWUtiPcqKhWj5EXWtZ7OuwrqOpVdY9lV8TfYLC0T1\nCPbhyH5e2ZdsixYtQuk1a9aE0qyRunx6sq7JdTr++OMj55QFcW0keQy4+pzL5HHIZbrGbro6cdql\niXA92T43rg9Vtuu0xqHrmGUz7LKrS1cH1jz52XLVk7U4q+3LAituJOP6nZ8nSyezbCLjxrL0gfvC\nqlPc2JU+eeJqmnHjhvqUKTtMIYQQogTRhCmEEEJ4oAlTCCGE8EATphBCCOFBrE0/lnE3GyS7BGXL\n0S6neRNQ3EC+LjGXjavZAJzvkzcJWU6u2RicHa0D0U09bLzNTgW4DK4jB8Hm/C6DcyvYNjtTKCss\nJ+M8JiyHGoDbiUZhuH24zLjO1nnDhysPOzr3CYRdGB4ztWrVSns9INrHVjBn3vTDm6N4DPGz4gp0\nwMe4rfg+ygJrgw3fp3W+i7gO3YviLMHCckxglWm9v12bxKwAGpaz9dKgqBum9IUphBBCeKAJUwgh\nhPBAE6YQQgjhQdoFa9ZxeP2btQbWL1xr03GdVltGzKx3WU6zgeg6O98HX5PX9fk++Zqsl7mMt9nR\nOefhenPAaA72zLrpSSedFEqvXbs2UgfWr+rWrRtKsyPussJy6m9pmKx5Arbjci4zroMNn3HLmiXX\nqVq1ammvwb+zrsbO11krAmwn9AUFBWnrzOfzNX0cgnMZHOTdFXS6tOG+4H0KluZVFD3RciJhXcPH\nYL+4dYqbdo05K+BGXEcEcR1AuOpVFCcPgL4whRBCCC80YQohhBAeaMIUQgghPEi7GMx2laxhss7D\n+ofL9s3Sflhb4vVovqaVZg0GiGqOrOXxfVpr5qxX+TigZh2Vnalv2bIlbR1ZK2K7TtY4WTMForom\nB4x22RKWBdyHPEb4d8t211UG57Gc/rvGUWF43LocqVv1dGmvhWFdjZ9PLs8VPJ3HMuvDrFtbewI4\nP9eJxykQHfv8vLgCrpc2paGbxQ1azJp0XJ3UZXcb9z4Y7u+i6KRxtdfi9oVPO/g4jXehL0whhBDC\nA02YQgghhAeaMIUQQggPKgQuwUcIIYQQIfSFKYQQQnigCVMIIYTwQBOmEEII4YEmTCGEEMIDTZhC\nCCGEB5owhRBCCA/+H7JeAHVieb4pAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "UaE2_6HUCAOw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We now train the descriptor model and save the weights afterward."
      ]
    },
    {
      "metadata": {
        "id": "QPyc8as42WTQ",
        "colab_type": "code",
        "outputId": "4cfef016-84cd-4e57-ea04-e6b63cfcd659",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1234
        }
      },
      "cell_type": "code",
      "source": [
        "epochs = 90\n",
        "### As with the denoising model, we use a loop to save for each epoch \n",
        "## #the weights in an external website in case colab stops. \n",
        "### reset, so e.g. calling 5 times fit(epochs=1) behave as fit(epochs=5)\n",
        "\n",
        "### If you have a model saved from a previous training session\n",
        "### Load it in the next line\n",
        "# descriptor_model_trip.set_weights(keras.models.load_model('./descriptor.h5').get_weights())\n",
        "# descriptor_model_trip.optimizer = keras.models.load_model('./descriptor.h5').optimizer\n",
        "\n",
        "history=[]\n",
        "for e in range(epochs):\n",
        "  \n",
        "  descriptor_history = descriptor_model_trip.fit_generator(generator=training_generator, epochs=1, verbose=1, validation_data=val_generator)\n",
        "  history.append(descriptor_history.history)\n",
        "  \n",
        "### Saves optimizer and weights\n",
        "descriptor_model_trip.save('descriptor_90.h5') \n",
        "### Uploads files to external hosting\n",
        "!curl -F \"file=@descriptor_90.h5\" https://file.io\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "  52/2000 [..............................] - ETA: 4:30 - loss: 0.3796"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-f40c27fe1750>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m   \u001b[0mdescriptor_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdescriptor_model_trip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m   \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdescriptor_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training_generator.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "m5ivayBJ4bvJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Plot results"
      ]
    },
    {
      "metadata": {
        "id": "aDqJhnRJ4dN8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Set empty lists\n",
        "training_loss=[]\n",
        "test_loss=[]\n",
        "\n",
        "#Get the data from the history list\n",
        "for i in range(len(history)):\n",
        "  # Get training and test loss for each one of histories\n",
        "  training_loss.append(history[i]['loss'])\n",
        "  test_loss.append(history[i]['val_loss'])\n",
        "\n",
        "# Create count of the number of epochs\n",
        "epoch_count = range(1, len(training_loss) + 1)\n",
        "\n",
        "# Visualize loss history\n",
        "plt.plot(epoch_count, training_loss, 'r--')\n",
        "plt.plot(epoch_count, test_loss, 'b--')\n",
        "plt.legend(['Training Loss', 'Validation Loss'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NJ-r9D4hDxij",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Generating descriptors files for test data \n",
        "\n",
        "To evaluate the performance of out model we will use an existing evaluation code, which is called HPatches benchmark. HPatches benchmark takes as input the descriptors for the test data in a CSV form. So the whole pipeline is represented in the following image.\n",
        "\n",
        "![](https://i.ibb.co/WcDDf3q/Screenshot-from-2019-02-15-11-17-24.png)\n",
        "\n",
        "This function generates those files by passing it a descriptor model and a denoising model. It performs a first step of denoising the patches, and a second one of computing the descriptor of the denoised patch. If no denoising model is given (variable set to `None`), the descriptor is computed directly in the noisy patch.\n",
        "\n",
        "Similarly to the loading data part, you have the denoise_model variable and `use_clean` variable. If `use_clean` is set to True, the CSV generated will be those of the clean patches, even if a denoising model is given. If set to False, then depends on the variable `denoise_model`. If there is no denoise model (`denoise_model=None`), then it will use the noisy patches. If you give a denoising model, then it will compute the CSV for the denoised patches. This can be useful to explore different scenarios (for example, the Upper Bound can be training the descriptor network with clean patches, and testing with clean patches), however you should always report the score when using noisy patches (depending on the approach you develop, you may want to denoise them or not). The official baseline uses the denoised patches. "
      ]
    },
    {
      "metadata": {
        "id": "kiJb2XDG9bsJ",
        "colab_type": "code",
        "outputId": "44209aa0-be20-4c05-8a39-2264b61cb08e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "generate_desc_csv(descriptor_model, seqs_test, denoise_model=denoise_model, use_clean=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [06:35<00:00, 11.25s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "s0jFr05rE1oI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Evaluating descriptors in HPatches Benchmark\n",
        "We use HPatches benchmark code to compute the results for our model. \n",
        "\n",
        "**Updated**: The necessary code is included in the repository we cloned at the beginning of the code, so we do not need to download any extra data. Also, we simplified the results, so now they only return one value for each of the three tasks."
      ]
    },
    {
      "metadata": {
        "id": "YvOGRh3sc9Wo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we will perform the evaluation of three different tasks (Verification, Matching and Evaluation) using the CSV files we generated as input and the `hpatches_eval.py` script. We also print the results using the `hpatches_results.py` script. The scripts will return a score for each of the tasks. The metric used is called mean Average Precision, which it uses the Precision of the model. The Precision is defined, for a given number of retrieved elements, as the ratio of correct retrieved elements / number of retrieved elements. [Link to Wikipedia with Precision explanation](https://en.wikipedia.org/wiki/Precision_and_recall). The definition of the three different tasks is taken from the [HPatches paper](https://arxiv.org/pdf/1704.05939.pdf).\n",
        "\n",
        "In all of the tasks if you use the optional argument `--more_info` in `hpatches_results.py` you can see extra mAP information. However, the important score is the mAP score reported without this flag.\n",
        "\n",
        "### Verification\n",
        "\n",
        "Patch verification measures the ability of a descriptor to classify whether two patches are extracted from the same measurement. Now we compute the score of our architecture in this task.\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Awnyv4xTYSFH",
        "colab_type": "code",
        "outputId": "be06d7d6-203a-44ac-9d00-bf10fe2c997e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "!python ./hpatches-benchmark/hpatches_eval.py --descr-name=custom --descr-dir=/content/keras_triplet_descriptor/out/ --task=verification --delimiter=\";\"\n",
        "!python ./hpatches-benchmark/hpatches_results.py --descr=custom --results-dir=./hpatches-benchmark/results/ --task=verification\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            ">> Running HPatch evaluation for \u001b[34mcustom\u001b[0m\n",
            ">> Please wait, loading the descriptor files...\n",
            ">> Descriptor files loaded.\n",
            ">> Evaluating \u001b[32mverification\u001b[0m task\n",
            "Processing verification task 1/3 : 100% 1000000/1000000 [01:32<00:00, 10865.68it/s]\n",
            "Processing verification task 2/3 : 100% 1000000/1000000 [01:30<00:00, 10992.03it/s]\n",
            "Processing verification task 3/3 : 100% 1000000/1000000 [01:31<00:00, 10900.89it/s]\n",
            ">> \u001b[32mVerification\u001b[0m task finished in 284 secs  \n",
            "\u001b[32mVerification\u001b[0m task results:\n",
            "Mean Average Precision is 0.714930\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5290Bw-udJdr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Matching\n",
        "Image matching, tests to what extent a descriptor can correctly identify correspondences in two images."
      ]
    },
    {
      "metadata": {
        "id": "EUqpwi87ckJv",
        "colab_type": "code",
        "outputId": "bae8823a-85dd-4c72-d162-bc294b20acb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "!python ./hpatches-benchmark/hpatches_eval.py --descr-name=custom --descr-dir=/content/keras_triplet_descriptor/out/ --task=matching --delimiter=\";\"\n",
        "!python ./hpatches-benchmark/hpatches_results.py --descr=custom --results-dir=./hpatches-benchmark/results/ --task=matching\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            ">> Running HPatch evaluation for \u001b[34mcustom\u001b[0m\n",
            ">> Please wait, loading the descriptor files...\n",
            ">> Descriptor files loaded.\n",
            ">> Evaluating \u001b[32mmatching\u001b[0m task\n",
            "100% 40/40 [02:07<00:00,  4.29s/it]\n",
            ">> \u001b[32mMatching\u001b[0m task finished in 127 secs  \n",
            "\u001b[32mMatching\u001b[0m task results:\n",
            "Mean Average Precision is 0.104292\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RXXgbN7DdMnx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Retrieval\n",
        "Retrieval tests how well a descriptor can match a query patch to a pool of patches extracted from many images."
      ]
    },
    {
      "metadata": {
        "id": "ZNmKIat1cn_M",
        "colab_type": "code",
        "outputId": "7e970d03-b631-4ab9-9a84-452031fc6ded",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "cell_type": "code",
      "source": [
        "!python ./hpatches-benchmark/hpatches_eval.py --descr-name=custom --descr-dir=/content/keras_triplet_descriptor/out/ --task=retrieval --delimiter=\";\"\n",
        "!python ./hpatches-benchmark/hpatches_results.py --descr=custom --results-dir=./hpatches-benchmark/results/ --task=retrieval"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            ">> Running HPatch evaluation for \u001b[34mcustom\u001b[0m\n",
            ">> Please wait, loading the descriptor files...\n",
            ">> Descriptor files loaded.\n",
            ">> Evaluating \u001b[32mretrieval\u001b[0m task\n",
            ">> Please wait, computing distance matrix...\n",
            "tcmalloc: large alloc 1600004096 bytes == 0x56234abbe000 @  0x7fd73548d1e7 0x7fd72b08ecf1 0x7fd72b0f13a2 0x7fd72b0f30de 0x7fd72b18a0e8 0x562323519fe5 0x56232350fd0a 0x5623235175fe 0x562323517232 0x56232350fd0a 0x562323517c38 0x56232350fd0a 0x56232350f629 0x56232354061f 0x56232353b322 0x56232353a67d 0x5623234e91ab 0x7fd73508ab97 0x5623234e8a2a\n",
            ">> Distance matrix done.\n",
            "Processing retrieval task: 100% 10000/10000 [03:57<00:00, 42.23it/s]\n",
            ">> \u001b[32mRetrieval\u001b[0m task finished in 276 secs  \n",
            "\u001b[32mRetrieval\u001b[0m task results:\n",
            "Mean Average Precision is 0.358950\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8_2fBzUB5RF2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Compressing and saving the CSV files \n",
        "\n",
        "This is not necessary for the analysis of the baseline code included in the report. However, we will be hosting a competition in an external website to see who can achieve the highest score. In that case, you will need to submit the CSV files, as the scoring script will be performed in an external server. With that aim, we include here a way to save the files either in your local disc or in your google drive account.\n",
        "\n",
        "We first compress the directory with all the CSV by using the following command. Remove the `q` option if you want it to output the progress."
      ]
    },
    {
      "metadata": {
        "id": "Lh_svT3p5Ww-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!zip -rq descriptors.zip ./out/custom"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "svoL779J8AJK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The generated .zip is quite large, the method we used for the weights does not work. We have two other methods. First, in the file explorer in the left column we can right-click in the file and then click download. Then, we will see a circle next to the file showing the download progress.\n",
        "\n",
        "The second way does not require for you to download the files, it save the zip file in your Google Drive account, and you can download it later to your machine if you want. To do so, follow this method (found [here](https://stackoverflow.com/questions/49428332/how-to-download-large-files-like-weights-of-a-model-from-colaboratory)). First run the next cell, and the output will be a link for authentication purposes, and just follow the instructions"
      ]
    },
    {
      "metadata": {
        "id": "RjOmPv5z7Opx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "auth.authenticate_user()\n",
        "drive_service = build('drive', 'v3')\n",
        "\n",
        "def save_file_to_drive(name, path):\n",
        "  file_metadata = {\n",
        "    'name': name,\n",
        "    'mimeType': 'application/octet-stream'\n",
        "  }\n",
        "\n",
        "  media = MediaFileUpload(path, \n",
        "                          mimetype='application/octet-stream',\n",
        "                          resumable=True)\n",
        "\n",
        "  created = drive_service.files().create(body=file_metadata,\n",
        "                                  media_body=media,\n",
        "                                  fields='id').execute()\n",
        "\n",
        "  print('File ID: {}'.format(created.get('id')))\n",
        "\n",
        "  return created\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YfzjfMc59NKm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we can use the following function to save the file to your drive account. The second argument is the name of the file we want to save, and the first argument the name that will have in your Drive."
      ]
    },
    {
      "metadata": {
        "id": "UwrqWr_c7pAi",
        "colab_type": "code",
        "outputId": "005994a0-bb3c-4c8d-dc93-91fdd94a4e98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "save_file_to_drive('descriptors_save.zip', 'descriptors.zip')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File ID: 1dHq0eDqoLMMmr6YOexZOU6cLwhFJYgH8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{u'id': u'1dHq0eDqoLMMmr6YOexZOU6cLwhFJYgH8'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "x78TXSB24DUl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Section 2\n",
        "\n",
        "There are different techniques used while experimenting. The DnCNN model below was used for denoise_model. TPE to fine-tune the L2-Net. "
      ]
    },
    {
      "metadata": {
        "id": "dTzGstTB5bJQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Tree of Parzen Estimators(TPE) method for L2-Net fine tuning"
      ]
    },
    {
      "metadata": {
        "id": "Lz0yoew-5QpV",
        "colab_type": "code",
        "outputId": "e6621e87-b7ca-4e7a-e30c-d366e178cc82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5818
        }
      },
      "cell_type": "code",
      "source": [
        "def create_model(training_generator, val_generator):\n",
        "  \n",
        "  from keras.layers import Lambda\n",
        "  \n",
        "  shape = (32, 32, 1)\n",
        "  \n",
        "  xa = Input(shape=shape, name='a')\n",
        "  xp = Input(shape=shape, name='p')\n",
        "  xn = Input(shape=shape, name='n')\n",
        "  \n",
        "  init_weights = keras.initializers.he_normal()\n",
        "  \n",
        "  descriptor_model = Sequential()\n",
        "  descriptor_model.add(Conv2D(32, 3, padding='same', input_shape=shape, use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation({{choice(['relu', 'sigmoid'])}}))\n",
        "\n",
        "  descriptor_model.add(Conv2D(32, 3, padding='same', use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation({{choice(['relu', 'sigmoid'])}}))\n",
        "\n",
        "  descriptor_model.add(Conv2D(64, 3, padding='same', strides=2, use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation({{choice(['relu', 'sigmoid'])}}))\n",
        "\n",
        "  descriptor_model.add(Conv2D(64, 3, padding='same', use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation({{choice(['relu', 'sigmoid'])}}))\n",
        "\n",
        "  descriptor_model.add(Conv2D(128, 3, padding='same', strides=2,  use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation({{choice(['relu', 'sigmoid'])}}))\n",
        "\n",
        "  descriptor_model.add(Conv2D(128, 3, padding='same', use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation({{choice(['relu', 'sigmoid'])}}))\n",
        "  descriptor_model.add(Dropout({{uniform(0, 1)}}))\n",
        "\n",
        "  descriptor_model.add(Conv2D(128, 8, padding='valid', use_bias = True, kernel_initializer=init_weights))\n",
        "  \n",
        "  # Final descriptor reshape\n",
        "  descriptor_model.add(Reshape((128,)))\n",
        "  \n",
        "  ea = descriptor_model(xa)\n",
        "  ep = descriptor_model(xp)\n",
        "  en = descriptor_model(xn)\n",
        "\n",
        "  loss = Lambda(yes.triplet_loss)([ea, ep, en])\n",
        "  \n",
        "  descriptor_model_trip = Model(inputs=[xa, xp, xn], output=loss)\n",
        "  \n",
        "  descriptor_model_trip.compile(loss='mean_absolute_error', optimizer={{choice(['rmsprop', 'adam', 'sgd'])}})\n",
        "  \n",
        "  result = descriptor_model_trip.fit_generator(generator=training_generator, epochs=20, verbose=2, validation_data=val_generator)\n",
        "  \n",
        "  #get the highest validation accuracy of the training epochs\n",
        "  validation_acc = np.amax(result.history['val_loss']) \n",
        "  print('Best validation acc of epoch:', validation_acc)\n",
        "  return {'loss': -validation_acc, 'status': STATUS_OK, 'model': descriptor_model_trip}\n",
        "\n",
        "def data():\n",
        "  \n",
        "  class My:\n",
        "    \n",
        "    def triplet_loss(self,x):\n",
        "      output_dim = 128\n",
        "      a, p, n = x\n",
        "      _alpha = 1.0\n",
        "      positive_distance = K.mean(K.square(a - p), axis=-1)\n",
        "      negative_distance = K.mean(K.square(a - n), axis=-1)\n",
        "      return K.expand_dims(K.maximum(0.0, positive_distance - negative_distance + _alpha), axis = 1)\n",
        "  \n",
        "  hpatches_dir = './hpatches'\n",
        "  splits_path = './splits.json'\n",
        "\n",
        "  splits_json = json.load(open(splits_path, 'rb'))\n",
        "  split = splits_json['a']\n",
        "\n",
        "  train_fnames = split['train']\n",
        "  test_fnames = split['test']\n",
        "\n",
        "  seqs = glob.glob(hpatches_dir+'/*')\n",
        "  seqs = [os.path.abspath(p) for p in seqs]   \n",
        "  seqs_train = list(filter(lambda x: x.split('/')[-1] in train_fnames, seqs)) \n",
        "  seqs_test = list(filter(lambda x: x.split('/')[-1] in split['test'], seqs)) \n",
        "  \n",
        "  ### Descriptor loading and training\n",
        "   # Loading images\n",
        "  hPatches = HPatches(train_fnames=train_fnames, test_fnames=test_fnames,\n",
        "                    denoise_model=None, use_clean=True)\n",
        "  # Creating training generator\n",
        "  training_generator = DataGeneratorDesc(*hPatches.read_image_file(hpatches_dir, train=1), num_triplets=1000)\n",
        "  # Creating validation generator\n",
        "  val_generator = DataGeneratorDesc(*hPatches.read_image_file(hpatches_dir, train=0), num_triplets=200)\n",
        "  \n",
        "  ##Hack to pass argument with class\n",
        "  yes=My()\n",
        "  \n",
        "  return training_generator, val_generator, yes\n",
        "  \n",
        "\n",
        "  \n",
        "best_run, best_model = optim.minimize(model=create_model,\n",
        "                                      data=data,\n",
        "                                      algo=tpe.suggest,\n",
        "                                      max_evals=10,\n",
        "                                      trials=Trials(),\n",
        "                                      notebook_name='Baseline_code')\n",
        "print(best_run)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>> Imports:\n",
            "#coding=utf-8\n",
            "\n",
            "try:\n",
            "    import psutil\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import humanize\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import os\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import GPUtil as GPU\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import sys\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import json\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import os\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import glob\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import time\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import tensorflow as tf\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import numpy as np\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import cv2\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import random\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import keras\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras import backend as K\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.models import Sequential, Model\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.layers import Dense, Dropout, Activation, Flatten, Input, Lambda, Reshape\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.layers import Input, UpSampling2D, concatenate\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from read_data import HPatches, DataGeneratorDesc, hpatches_sequence_folder, DenoiseHPatches, tps\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from utils import generate_desc_csv, plot_denoise, plot_triplet\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from google.colab import files\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.layers import Lambda\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from google.colab import auth\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from googleapiclient.http import MediaFileUpload\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from googleapiclient.discovery import build\n",
            "except:\n",
            "    pass\n",
            "\n",
            ">>> Hyperas search space:\n",
            "\n",
            "def get_space():\n",
            "    return {\n",
            "        'Activation': hp.choice('Activation', ['relu', 'sigmoid']),\n",
            "        'Activation_1': hp.choice('Activation_1', ['relu', 'sigmoid']),\n",
            "        'Activation_2': hp.choice('Activation_2', ['relu', 'sigmoid']),\n",
            "        'Activation_3': hp.choice('Activation_3', ['relu', 'sigmoid']),\n",
            "        'Activation_4': hp.choice('Activation_4', ['relu', 'sigmoid']),\n",
            "        'Activation_5': hp.choice('Activation_5', ['relu', 'sigmoid']),\n",
            "        'Dropout': hp.uniform('Dropout', 0, 1),\n",
            "        'optimizer': hp.choice('optimizer', ['rmsprop', 'adam', 'sgd']),\n",
            "    }\n",
            "\n",
            ">>> Data\n",
            "   1: \n",
            "   2: \n",
            "   3: class My:\n",
            "   4:   \n",
            "   5:   def triplet_loss(self,x):\n",
            "   6:     output_dim = 128\n",
            "   7:     a, p, n = x\n",
            "   8:     _alpha = 1.0\n",
            "   9:     positive_distance = K.mean(K.square(a - p), axis=-1)\n",
            "  10:     negative_distance = K.mean(K.square(a - n), axis=-1)\n",
            "  11:     return K.expand_dims(K.maximum(0.0, positive_distance - negative_distance + _alpha), axis = 1)\n",
            "  12: \n",
            "  13: hpatches_dir = './hpatches'\n",
            "  14: splits_path = './splits.json'\n",
            "  15: \n",
            "  16: splits_json = json.load(open(splits_path, 'rb'))\n",
            "  17: split = splits_json['a']\n",
            "  18: \n",
            "  19: train_fnames = split['train']\n",
            "  20: test_fnames = split['test']\n",
            "  21: \n",
            "  22: seqs = glob.glob(hpatches_dir+'/*')\n",
            "  23: seqs = [os.path.abspath(p) for p in seqs]   \n",
            "  24: seqs_train = list(filter(lambda x: x.split('/')[-1] in train_fnames, seqs)) \n",
            "  25: seqs_test = list(filter(lambda x: x.split('/')[-1] in split['test'], seqs)) \n",
            "  26: \n",
            "  27: ### Descriptor loading and training\n",
            "  28:  # Loading images\n",
            "  29: hPatches = HPatches(train_fnames=train_fnames, test_fnames=test_fnames,\n",
            "  30:                   denoise_model=None, use_clean=True)\n",
            "  31: # Creating training generator\n",
            "  32: training_generator = DataGeneratorDesc(*hPatches.read_image_file(hpatches_dir, train=1), num_triplets=1000)\n",
            "  33: # Creating validation generator\n",
            "  34: val_generator = DataGeneratorDesc(*hPatches.read_image_file(hpatches_dir, train=0), num_triplets=200)\n",
            "  35: \n",
            "  36: ##Hack to pass argument with class\n",
            "  37: yes=My()\n",
            "  38: \n",
            "  39: \n",
            "  40: \n",
            "  41: \n",
            ">>> Resulting replaced keras model:\n",
            "\n",
            "   1: def keras_fmin_fnct(space):\n",
            "   2: \n",
            "   3:   \n",
            "   4:   \n",
            "   5:   shape = (32, 32, 1)\n",
            "   6:   \n",
            "   7:   xa = Input(shape=shape, name='a')\n",
            "   8:   xp = Input(shape=shape, name='p')\n",
            "   9:   xn = Input(shape=shape, name='n')\n",
            "  10:   \n",
            "  11:   init_weights = keras.initializers.he_normal()\n",
            "  12:   \n",
            "  13:   descriptor_model = Sequential()\n",
            "  14:   descriptor_model.add(Conv2D(32, 3, padding='same', input_shape=shape, use_bias = True, kernel_initializer=init_weights))\n",
            "  15:   descriptor_model.add(BatchNormalization(axis = -1))\n",
            "  16:   descriptor_model.add(Activation(space['Activation']))\n",
            "  17: \n",
            "  18:   descriptor_model.add(Conv2D(32, 3, padding='same', use_bias = True, kernel_initializer=init_weights))\n",
            "  19:   descriptor_model.add(BatchNormalization(axis = -1))\n",
            "  20:   descriptor_model.add(Activation(space['Activation_1']))\n",
            "  21: \n",
            "  22:   descriptor_model.add(Conv2D(64, 3, padding='same', strides=2, use_bias = True, kernel_initializer=init_weights))\n",
            "  23:   descriptor_model.add(BatchNormalization(axis = -1))\n",
            "  24:   descriptor_model.add(Activation(space['Activation_2']))\n",
            "  25: \n",
            "  26:   descriptor_model.add(Conv2D(64, 3, padding='same', use_bias = True, kernel_initializer=init_weights))\n",
            "  27:   descriptor_model.add(BatchNormalization(axis = -1))\n",
            "  28:   descriptor_model.add(Activation(space['Activation_3']))\n",
            "  29: \n",
            "  30:   descriptor_model.add(Conv2D(128, 3, padding='same', strides=2,  use_bias = True, kernel_initializer=init_weights))\n",
            "  31:   descriptor_model.add(BatchNormalization(axis = -1))\n",
            "  32:   descriptor_model.add(Activation(space['Activation_4']))\n",
            "  33: \n",
            "  34:   descriptor_model.add(Conv2D(128, 3, padding='same', use_bias = True, kernel_initializer=init_weights))\n",
            "  35:   descriptor_model.add(BatchNormalization(axis = -1))\n",
            "  36:   descriptor_model.add(Activation(space['Activation_5']))\n",
            "  37:   descriptor_model.add(Dropout(space['Dropout']))\n",
            "  38: \n",
            "  39:   descriptor_model.add(Conv2D(128, 8, padding='valid', use_bias = True, kernel_initializer=init_weights))\n",
            "  40:   \n",
            "  41:   # Final descriptor reshape\n",
            "  42:   descriptor_model.add(Reshape((128,)))\n",
            "  43:   \n",
            "  44:   ea = descriptor_model(xa)\n",
            "  45:   ep = descriptor_model(xp)\n",
            "  46:   en = descriptor_model(xn)\n",
            "  47: \n",
            "  48:   loss = Lambda(yes.triplet_loss)([ea, ep, en])\n",
            "  49:   \n",
            "  50:   descriptor_model_trip = Model(inputs=[xa, xp, xn], output=loss)\n",
            "  51:   \n",
            "  52:   descriptor_model_trip.compile(loss='mean_absolute_error', optimizer=space['optimizer'])\n",
            "  53:   \n",
            "  54:   result = descriptor_model_trip.fit_generator(generator=training_generator, epochs=20, verbose=2, validation_data=val_generator)\n",
            "  55:   \n",
            "  56:   #get the highest validation accuracy of the training epochs\n",
            "  57:   validation_acc = np.amax(result.history['val_loss']) \n",
            "  58:   print('Best validation acc of epoch:', validation_acc)\n",
            "  59:   return {'loss': -validation_acc, 'status': STATUS_OK, 'model': descriptor_model_trip}\n",
            "  60: \n",
            "Using clean patches\n",
            "\n",
            "  0%|          | 0/116 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 1/116 [00:00<01:14,  1.54it/s]\u001b[A\n",
            "  3%|▎         | 3/116 [00:01<01:03,  1.78it/s]\u001b[A\n",
            "  3%|▎         | 4/116 [00:01<00:59,  1.89it/s]\u001b[A\n",
            "  6%|▌         | 7/116 [00:02<00:42,  2.56it/s]\u001b[A\n",
            "  8%|▊         | 9/116 [00:02<00:40,  2.64it/s]\u001b[A\n",
            "  9%|▊         | 10/116 [00:03<00:52,  2.03it/s]\u001b[A\n",
            "  9%|▉         | 11/116 [00:03<00:51,  2.05it/s]\u001b[A\n",
            " 10%|█         | 12/116 [00:04<00:42,  2.46it/s]\u001b[A\n",
            " 12%|█▏        | 14/116 [00:04<00:39,  2.59it/s]\u001b[A\n",
            " 14%|█▍        | 16/116 [00:05<00:33,  3.01it/s]\u001b[A\n",
            " 15%|█▍        | 17/116 [00:05<00:39,  2.48it/s]\u001b[A\n",
            " 16%|█▌        | 18/116 [00:06<00:35,  2.76it/s]\u001b[A\n",
            " 17%|█▋        | 20/116 [00:06<00:28,  3.39it/s]\u001b[AUnexpected error: <type 'exceptions.KeyboardInterrupt'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-307f7ec15272>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    106\u001b[0m                                       \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m                                       \u001b[0mtrials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m                                       notebook_name='Baseline_code')\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_run\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/hyperas/optim.pyc\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(model, data, algo, max_evals, trials, functions, rseed, notebook_name, verbose, eval_space, return_space, keep_temp)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                      \u001b[0mnotebook_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnotebook_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                                      \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                                      keep_temp=keep_temp)\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/hyperas/optim.pyc\u001b[0m in \u001b[0;36mbase_minimizer\u001b[0;34m(model, data, functions, algo, max_evals, trials, rseed, full_model_string, notebook_name, verbose, stack, keep_temp)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mtemp_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras_fmin_fnct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unexpected error: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/keras_triplet_descriptor/temp_model.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    162\u001b[0m                   denoise_model=None, use_clean=True)\n\u001b[1;32m    163\u001b[0m \u001b[0;31m# Creating training generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m \u001b[0mtraining_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataGeneratorDesc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mhPatches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_image_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhpatches_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_triplets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;31m# Creating validation generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0mval_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataGeneratorDesc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mhPatches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_image_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhpatches_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_triplets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/keras_triplet_descriptor/read_data.py\u001b[0m in \u001b[0;36mread_image_file\u001b[0;34m(self, data_dir, train)\u001b[0m\n\u001b[1;32m    185\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m                     \u001b[0msequence_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_noise.png'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m                 \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m                 \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m                 \u001b[0mn_patches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "G5mAMc8o55nO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##DnCNN\n"
      ]
    },
    {
      "metadata": {
        "id": "4Ol7bU3O7EpF",
        "colab_type": "code",
        "outputId": "88754316-d42f-4341-b850-2739c97006d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3234
        }
      },
      "cell_type": "code",
      "source": [
        "def DnCNN(depth,filters=64,image_channels=1, use_bnorm=True):\n",
        "    layer_count = 0\n",
        "    inpt = Input(shape=(None,None,image_channels),name = 'input'+str(layer_count))\n",
        "    # 1st layer, Conv+relu\n",
        "    layer_count += 1\n",
        "    x = Conv2D(filters=filters, kernel_size=(3,3), strides=(1,1),kernel_initializer='Orthogonal', padding='same',name = 'conv'+str(layer_count))(inpt)\n",
        "    layer_count += 1\n",
        "    x = Activation('relu',name = 'relu'+str(layer_count))(x)\n",
        "    \n",
        "    # depth-2 layers, Conv+BN+relu\n",
        "    for i in range(depth-2):\n",
        "        layer_count += 1\n",
        "        x = Conv2D(filters=filters, kernel_size=(3,3), strides=(1,1),kernel_initializer='Orthogonal', padding='same',use_bias = False,name = 'conv'+str(layer_count))(x)\n",
        "        if use_bnorm:\n",
        "            layer_count += 1\n",
        "            x = BatchNormalization(axis=3, momentum=0.0,epsilon=0.0001, name = 'bn'+str(layer_count))(x)\n",
        "        layer_count += 1\n",
        "        x = Activation('relu',name = 'relu'+str(layer_count))(x)  \n",
        "    \n",
        "    # last layer, Conv\n",
        "    layer_count += 1\n",
        "    x = Conv2D(filters=image_channels, kernel_size=(3,3), strides=(1,1), kernel_initializer='Orthogonal',padding='same',use_bias = False,name = 'conv'+str(layer_count))(x)\n",
        "    layer_count += 1\n",
        "    \n",
        "    # input - noise\n",
        "    x = Subtract(name = 'subtract' + str(layer_count))([inpt, x]) \n",
        "    \n",
        "    model = Model(inputs=inpt, outputs=x)\n",
        "    return model\n",
        "  \n",
        "    \n",
        "def sum_squared_error(y_true, y_pred):\n",
        "    return K.sum(K.square(y_pred - y_true))/2\n",
        "  \n",
        "  \n",
        "# model selection\n",
        "modelDNN = DnCNN(depth=17, filters=64, image_channels=1, use_bnorm=True)\n",
        "modelDNN.summary()  \n",
        "  \n",
        "\n",
        "# compile the model\n",
        "modelDNN.compile(optimizer=Adam(0.001), loss=sum_squared_error)\n",
        "\n",
        "# lr decay\n",
        "def lr_schedule(epoch):\n",
        "    initial_lr = 0.001\n",
        "    if epoch<=30:\n",
        "        lr = initial_lr/100\n",
        "    elif epoch<=60:\n",
        "        lr = initial_lr/10\n",
        "    elif epoch<=80:\n",
        "        lr = initial_lr/20 \n",
        "    else:\n",
        "        lr = initial_lr/20 \n",
        "    return lr\n",
        "        \n",
        "\n",
        "change_lr = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "#Train the model\n",
        "\n",
        "epochs = 50\n",
        "history=[]\n",
        "for e in range(epochs):\n",
        "  denoise_history = modelDNN.fit_generator(generator=denoise_generator, \n",
        "                                                epochs=1, verbose=1, \n",
        "                                                validation_data=denoise_generator_val)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input0 (InputLayer)             (None, None, None, 1 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, None, None, 6 640         input0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "relu2 (Activation)              (None, None, None, 6 0           conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv3 (Conv2D)                  (None, None, None, 6 36864       relu2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "bn4 (BatchNormalization)        (None, None, None, 6 256         conv3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "relu5 (Activation)              (None, None, None, 6 0           bn4[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv6 (Conv2D)                  (None, None, None, 6 36864       relu5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "bn7 (BatchNormalization)        (None, None, None, 6 256         conv6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "relu8 (Activation)              (None, None, None, 6 0           bn7[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv9 (Conv2D)                  (None, None, None, 6 36864       relu8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "bn10 (BatchNormalization)       (None, None, None, 6 256         conv9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "relu11 (Activation)             (None, None, None, 6 0           bn10[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "conv12 (Conv2D)                 (None, None, None, 6 36864       relu11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bn13 (BatchNormalization)       (None, None, None, 6 256         conv12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "relu14 (Activation)             (None, None, None, 6 0           bn13[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "conv15 (Conv2D)                 (None, None, None, 6 36864       relu14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bn16 (BatchNormalization)       (None, None, None, 6 256         conv15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "relu17 (Activation)             (None, None, None, 6 0           bn16[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "conv18 (Conv2D)                 (None, None, None, 6 36864       relu17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bn19 (BatchNormalization)       (None, None, None, 6 256         conv18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "relu20 (Activation)             (None, None, None, 6 0           bn19[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "conv21 (Conv2D)                 (None, None, None, 6 36864       relu20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bn22 (BatchNormalization)       (None, None, None, 6 256         conv21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "relu23 (Activation)             (None, None, None, 6 0           bn22[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "conv24 (Conv2D)                 (None, None, None, 6 36864       relu23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bn25 (BatchNormalization)       (None, None, None, 6 256         conv24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "relu26 (Activation)             (None, None, None, 6 0           bn25[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "conv27 (Conv2D)                 (None, None, None, 6 36864       relu26[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bn28 (BatchNormalization)       (None, None, None, 6 256         conv27[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "relu29 (Activation)             (None, None, None, 6 0           bn28[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "conv30 (Conv2D)                 (None, None, None, 6 36864       relu29[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bn31 (BatchNormalization)       (None, None, None, 6 256         conv30[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "relu32 (Activation)             (None, None, None, 6 0           bn31[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "conv33 (Conv2D)                 (None, None, None, 6 36864       relu32[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bn34 (BatchNormalization)       (None, None, None, 6 256         conv33[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "relu35 (Activation)             (None, None, None, 6 0           bn34[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "conv36 (Conv2D)                 (None, None, None, 6 36864       relu35[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bn37 (BatchNormalization)       (None, None, None, 6 256         conv36[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "relu38 (Activation)             (None, None, None, 6 0           bn37[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "conv39 (Conv2D)                 (None, None, None, 6 36864       relu38[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bn40 (BatchNormalization)       (None, None, None, 6 256         conv39[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "relu41 (Activation)             (None, None, None, 6 0           bn40[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "conv42 (Conv2D)                 (None, None, None, 6 36864       relu41[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bn43 (BatchNormalization)       (None, None, None, 6 256         conv42[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "relu44 (Activation)             (None, None, None, 6 0           bn43[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "conv45 (Conv2D)                 (None, None, None, 6 36864       relu44[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bn46 (BatchNormalization)       (None, None, None, 6 256         conv45[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "relu47 (Activation)             (None, None, None, 6 0           bn46[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "conv48 (Conv2D)                 (None, None, None, 1 576         relu47[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "subtract49 (Subtract)           (None, None, None, 1 0           input0[0][0]                     \n",
            "                                                                 conv48[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 558,016\n",
            "Trainable params: 556,096\n",
            "Non-trainable params: 1,920\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/1\n",
            "  14/1458 [..............................] - ETA: 9:31 - loss: 11310398.0000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-71f55cb86453>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m   denoise_history = modelDNN.fit_generator(generator=denoise_generator, \n\u001b[1;32m     66\u001b[0m                                                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                                                 validation_data=denoise_generator_val)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training_generator.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}